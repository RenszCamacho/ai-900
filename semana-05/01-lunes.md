# AI-900 Certification - Semana 5, D√≠a 1

## Introducci√≥n a la IA Generativa (Generative AI)

**Fecha:** Lunes, Semana 5  
**Duraci√≥n estimada:** 45-60 minutos  
**Nivel:** Fundamental

---

## üìã Objetivos del d√≠a

- Comprender qu√© es la IA Generativa y c√≥mo funciona
- Conocer los tipos de modelos generativos
- Entender las diferencias entre IA tradicional vs IA Generativa
- Identificar casos de uso comunes de IA Generativa
- Conocer los conceptos fundamentales de Large Language Models (LLMs)

---

## 1. ¬øQu√© es la IA Generativa?

### Definici√≥n

La **IA Generativa** es un tipo de inteligencia artificial que puede crear contenido nuevo y original, incluyendo:
- Texto (art√≠culos, c√≥digo, emails)
- Im√°genes (arte, fotograf√≠as, dise√±os)
- Audio (m√∫sica, voz, efectos de sonido)
- Video (animaciones, clips)
- C√≥digo (programas, scripts)

### ¬øC√≥mo funciona?

Los modelos generativos aprenden patrones de grandes cantidades de datos de entrenamiento y luego pueden generar contenido similar pero nuevo.

**Proceso b√°sico:**
1. **Entrenamiento**: El modelo analiza millones de ejemplos
2. **Aprendizaje de patrones**: Identifica estructuras, estilos, relaciones
3. **Generaci√≥n**: Crea contenido nuevo basado en esos patrones
4. **Refinamiento**: Ajusta la salida seg√∫n instrucciones (prompts)

---

## 2. IA Tradicional vs IA Generativa

### IA Tradicional (Predictiva/Anal√≠tica)

**Prop√≥sito**: Analizar, clasificar, predecir

**Ejemplos:**
- Clasificaci√≥n de emails (spam vs no spam)
- Predicci√≥n de ventas
- Detecci√≥n de fraude
- Reconocimiento de objetos en im√°genes

**Salida**: Etiquetas, categor√≠as, n√∫meros, predicciones

**Ejemplo pr√°ctico:**
```
Input: Imagen de un gato
Output: "Gato" (clasificaci√≥n)
```

### IA Generativa

**Prop√≥sito**: Crear, generar, sintetizar

**Ejemplos:**
- Generar art√≠culos o historias
- Crear im√°genes a partir de descripciones
- Escribir c√≥digo
- Componer m√∫sica

**Salida**: Contenido nuevo y original

**Ejemplo pr√°ctico:**
```
Input: "Escribe un poema sobre el oc√©ano"
Output: Un poema completo y √∫nico sobre el oc√©ano
```

### Comparaci√≥n visual

| Aspecto | IA Tradicional | IA Generativa |
|---------|----------------|---------------|
| **Funci√≥n principal** | Analizar y predecir | Crear y generar |
| **Entrada** | Datos para clasificar | Prompts/Instrucciones |
| **Salida** | Etiquetas, n√∫meros | Contenido nuevo |
| **Ejemplo** | "Esta imagen es un perro" | "Crea una imagen de un perro" |
| **Modelos t√≠picos** | Random Forest, SVM | GPT, DALL-E, Stable Diffusion |

---

## 3. Tipos de Modelos Generativos

### 1. Large Language Models (LLMs)

**Descripci√≥n**: Modelos entrenados en enormes cantidades de texto

**Ejemplos:**
- **GPT (Generative Pre-trained Transformer)**: GPT-3.5, GPT-4
- **BERT**: Bidirectional Encoder Representations
- **LLaMA**: Meta's Large Language Model

**Capacidades:**
- Generaci√≥n de texto coherente
- Traducci√≥n de idiomas
- Resumen de documentos
- Respuesta a preguntas
- Generaci√≥n de c√≥digo

**Caso de uso:**
```
Prompt: "Explica la fotos√≠ntesis para un ni√±o de 8 a√±os"
Output: Respuesta adaptada al nivel apropiado
```

### 2. Modelos de Generaci√≥n de Im√°genes

**Descripci√≥n**: Crean im√°genes a partir de descripciones de texto

**Ejemplos:**
- **DALL-E**: OpenAI
- **Stable Diffusion**: Stability AI
- **Midjourney**: Midjourney Inc.

**Capacidades:**
- Generaci√≥n de arte digital
- Modificaci√≥n de im√°genes existentes
- Creaci√≥n de variaciones
- Inpainting (rellenar partes faltantes)

**Caso de uso:**
```
Prompt: "Un astronauta montando un caballo en Marte, estilo acuarela"
Output: Imagen generada seg√∫n descripci√≥n
```

### 3. Modelos Multimodales

**Descripci√≥n**: Trabajan con m√∫ltiples tipos de datos (texto, imagen, audio)

**Ejemplos:**
- **GPT-4 Vision**: Texto + Im√°genes
- **CLIP**: Relaciona im√°genes y texto
- **Flamingo**: M√∫ltiples modalidades

**Capacidades:**
- Describir im√°genes
- Generar im√°genes desde texto
- Responder preguntas sobre im√°genes
- An√°lisis de contenido multimedia

---

## 4. Conceptos Fundamentales de LLMs

### Tokens

**¬øQu√© son?**
Los tokens son las unidades b√°sicas de procesamiento de texto en LLMs.

**Ejemplos de tokenizaci√≥n:**
```
"Hola mundo" ‚Üí ["Hola", " mundo"] = 2 tokens
"OpenAI" ‚Üí ["Open", "AI"] = 2 tokens
"¬°Fant√°stico!" ‚Üí ["¬°", "Fant", "√°stico", "!"] = 4 tokens
```

**Regla general**: 
- En ingl√©s: ~1 token = 4 caracteres = 0.75 palabras
- En espa√±ol: ~1 token = 3-4 caracteres

**Importancia**: 
- Los modelos tienen l√≠mites de tokens (ej: GPT-4 = 8k, 32k, 128k tokens)
- El costo de uso se calcula por tokens

### Context Window (Ventana de Contexto)

**Definici√≥n**: Cantidad m√°xima de tokens que un modelo puede procesar a la vez

**Ejemplos:**
- GPT-3.5: 4,096 tokens (~3,000 palabras)
- GPT-4: 8,192 - 128,000 tokens
- Claude 2: 100,000 tokens

**Implicaci√≥n pr√°ctica:**
Si un documento tiene m√°s tokens que la ventana de contexto, el modelo no puede procesarlo completo en una sola solicitud.

### Temperatura

**Definici√≥n**: Par√°metro que controla la aleatoriedad/creatividad de las respuestas

**Escala**: 0.0 - 2.0

**Comportamiento:**
- **Temperatura baja (0.0 - 0.3)**: 
  - Respuestas m√°s predecibles y deterministas
  - √ötil para: Tareas t√©cnicas, clasificaci√≥n, extracci√≥n de datos
  
- **Temperatura media (0.5 - 0.8)**:
  - Balance entre creatividad y coherencia
  - √ötil para: Conversaci√≥n general, escritura
  
- **Temperatura alta (1.0 - 2.0)**:
  - Respuestas muy creativas y variadas
  - √ötil para: Brainstorming, contenido creativo, arte

**Ejemplo:**
```
Prompt: "Termina la frase: El cielo es..."

Temperatura 0.0: "azul" (siempre la misma)
Temperatura 0.7: "azul", "hermoso", "infinito" (variado pero sensato)
Temperatura 1.5: "un lienzo de sue√±os", "esperanza l√≠quida" (muy creativo)
```

### Embeddings

**Definici√≥n**: Representaciones num√©ricas (vectores) de texto que capturan significado sem√°ntico

**Caracter√≠sticas:**
- Palabras similares tienen embeddings similares
- Permiten buscar por significado, no solo por palabras exactas
- √ötiles para: b√∫squeda sem√°ntica, recomendaciones, clustering

**Ejemplo conceptual:**
```
"perro" ‚Üí [0.2, 0.8, 0.1, 0.9, ...]
"gato"  ‚Üí [0.3, 0.7, 0.2, 0.8, ...] (similar)
"carro" ‚Üí [0.8, 0.1, 0.9, 0.2, ...] (diferente)
```

---

## 5. Casos de Uso Comunes

### Generaci√≥n de Contenido
- Art√≠culos de blog
- Descripciones de productos
- Posts para redes sociales
- Guiones de video

### Asistencia al Cliente
- Chatbots inteligentes
- Respuestas autom√°ticas a emails
- FAQs din√°micas
- Soporte multiling√ºe

### Desarrollo de Software
- Generaci√≥n de c√≥digo
- Documentaci√≥n autom√°tica
- Debugging y explicaci√≥n de c√≥digo
- Refactorizaci√≥n

### Creaci√≥n de Contenido Visual
- Prototipos de dise√±o
- Arte generativo
- Edici√≥n de im√°genes
- Creaci√≥n de avatares

### Educaci√≥n
- Tutores virtuales personalizados
- Generaci√≥n de ejercicios
- Explicaciones adaptadas al nivel
- Traducci√≥n de materiales educativos

### An√°lisis y Resumen
- Resumen de documentos largos
- Extracci√≥n de informaci√≥n clave
- An√°lisis de sentimientos
- S√≠ntesis de reuniones

---

## 6. Limitaciones de la IA Generativa

### Alucinaciones (Hallucinations)

**Problema**: Los modelos pueden generar informaci√≥n falsa pero convincente

**Ejemplo:**
```
Pregunta: "¬øQui√©n gan√≥ el Premio Nobel de Literatura en 2025?"
Respuesta incorrecta: "Mar√≠a Garc√≠a lo gan√≥ por su novela 'El Tiempo Perdido'"
(Inventa nombres y datos que suenan plausibles)
```

**Mitigaci√≥n:**
- Verificar informaci√≥n cr√≠tica
- Usar grounding (anclar a datos reales)
- Pedir fuentes y referencias

### Sesgos

**Problema**: Los modelos reflejan sesgos presentes en datos de entrenamiento

**Ejemplos:**
- Sesgos de g√©nero en profesiones
- Sesgos culturales o raciales
- Representaci√≥n desigual de idiomas

**Mitigaci√≥n:**
- Datos de entrenamiento diversos
- Fine-tuning responsable
- Revisi√≥n humana

### Falta de Razonamiento Verdadero

**Problema**: Los modelos reconocen patrones, no "entienden" realmente

**Limitaciones:**
- No tienen conocimiento del mundo real actualizado
- No pueden razonar causalmente de forma confiable
- No tienen sentido com√∫n verdadero

### Costos y Recursos

**Consideraciones:**
- Entrenamiento requiere recursos computacionales masivos
- Inferencia (uso) tambi√©n consume recursos significativos
- Costos por token en APIs comerciales

---

## ‚úÖ Puntos Clave para el Examen

- IA Generativa **crea contenido nuevo**, IA tradicional **analiza y predice**
- **LLMs** (Large Language Models) son modelos entrenados en texto masivo
- **Tokens** son unidades b√°sicas de procesamiento (~4 caracteres en ingl√©s)
- **Context Window** es el l√≠mite de tokens que un modelo puede procesar
- **Temperatura** controla creatividad (baja = predecible, alta = creativo)
- **Embeddings** son representaciones vectoriales que capturan significado
- **Alucinaciones** = informaci√≥n falsa pero convincente generada por el modelo
- Casos de uso: generaci√≥n de contenido, chatbots, c√≥digo, im√°genes, res√∫menes
- Limitaciones: alucinaciones, sesgos, falta de razonamiento real, costos

---

## üéØ Preguntas Estilo Examen Microsoft AI-900

### Pregunta 1
¬øCu√°l de las siguientes afirmaciones describe MEJOR la diferencia entre IA tradicional e IA generativa?

A) La IA tradicional es m√°s r√°pida que la IA generativa  
B) La IA tradicional analiza y predice, mientras que la IA generativa crea contenido nuevo  
C) La IA generativa solo funciona con texto  
D) La IA tradicional requiere m√°s datos de entrenamiento

**Respuesta correcta: B) La IA tradicional analiza y predice, mientras que la IA generativa crea contenido nuevo**

**Explicaci√≥n**: La diferencia fundamental es el prop√≥sito: la IA tradicional (clasificaci√≥n, regresi√≥n) analiza datos existentes para hacer predicciones o clasificaciones. La IA generativa crea contenido nuevo (texto, im√°genes, c√≥digo) bas√°ndose en patrones aprendidos. Las opciones A, C y D no representan las diferencias fundamentales entre ambos tipos de IA.

---

### Pregunta 2
Est√°s configurando un modelo de lenguaje para generar respuestas de servicio al cliente. Necesitas que las respuestas sean consistentes y predecibles. ¬øQu√© valor de temperatura deber√≠as usar?

A) 2.0  
B) 1.5  
C) 0.8  
D) 0.2

**Respuesta correcta: D) 0.2**

**Explicaci√≥n**: Para respuestas consistentes y predecibles, necesitas una temperatura **baja** (cercana a 0). Valores bajos como 0.2 hacen que el modelo seleccione las opciones m√°s probables, resultando en respuestas deterministas y confiables. Temperaturas altas (1.5, 2.0) generan respuestas m√°s creativas pero menos predecibles, inapropiado para servicio al cliente donde la consistencia es clave.

---

### Pregunta 3
Un modelo de lenguaje genera la siguiente respuesta: "El Monte Everest est√° ubicado en Jap√≥n y tiene una altura de 12,000 metros." ¬øQu√© problema est√° demostrando este modelo?

A) Baja temperatura  
B) Alucinaciones (Hallucinations)  
C) Falta de tokens  
D) Contexto insuficiente

**Respuesta correcta: B) Alucinaciones (Hallucinations)**

**Explicaci√≥n**: Las **alucinaciones** ocurren cuando un modelo genera informaci√≥n falsa pero convincente. El Everest est√° en Nepal/Tibet (no Jap√≥n) y mide ~8,849 metros (no 12,000). El modelo est√° inventando "hechos" plausibles pero incorrectos. Esto es diferente de problemas de temperatura (controla creatividad), falta de tokens (l√≠mite de procesamiento), o contexto insuficiente (informaci√≥n de entrada limitada).

---

### Pregunta 4
¬øQu√© son los "tokens" en el contexto de Large Language Models?

A) Medidas de la calidad del modelo  
B) Unidades b√°sicas de procesamiento de texto  
C) Nombres de los modelos de IA  
D) Par√°metros de configuraci√≥n del modelo

**Respuesta correcta: B) Unidades b√°sicas de procesamiento de texto**

**Explicaci√≥n**: Los **tokens** son las unidades fundamentales en las que los LLMs dividen el texto para procesarlo. Una palabra puede ser uno o varios tokens dependiendo de su longitud y composici√≥n. Por ejemplo, "Hola" = 1 token, "Fant√°stico" = 2-3 tokens. Los tokens determinan los l√≠mites de procesamiento del modelo (context window) y los costos de uso. No son medidas de calidad, nombres de modelos, ni par√°metros de configuraci√≥n.

---

### Pregunta 5
Una empresa quiere usar IA generativa para crear descripciones √∫nicas de productos basadas en especificaciones t√©cnicas. ¬øCu√°l de los siguientes es un caso de uso apropiado para IA generativa?

A) Clasificar productos en categor√≠as existentes  
B) Predecir la demanda futura de productos  
C) Generar textos descriptivos creativos y √∫nicos para cada producto  
D) Analizar sentimientos de reviews de clientes

**Respuesta correcta: C) Generar textos descriptivos creativos y √∫nicos para cada producto**

**Explicaci√≥n**: La IA generativa es ideal para **crear contenido nuevo y original**, como descripciones de productos. Las otras opciones son tareas de IA tradicional: clasificaci√≥n (A), predicci√≥n (B), y an√°lisis de sentimientos (D) son tareas de IA predictiva/anal√≠tica que no requieren generar contenido nuevo, solo analizar y categorizar datos existentes.

---

## üìö Tarea para ma√±ana

Ma√±ana profundizaremos en **Azure OpenAI Service**: deployment de modelos, APIs, Studio, y casos de uso pr√°cticos.

---

## üìñ Recursos Adicionales

- [Microsoft Learn - AI-900 Learning Path](https://docs.microsoft.com/learn/certifications/exams/ai-900)
- [Azure AI Services Documentation](https://docs.microsoft.com/azure/cognitive-services/)
- [Responsible AI Resources](https://www.microsoft.com/ai/responsible-ai)
- [Transparency Notes](https://docs.microsoft.com/azure/cognitive-services/transparency-note)

---

**Semana:** 5 de 6  
**Pr√≥ximo tema:** Azure OpenAI Service
