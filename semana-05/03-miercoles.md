# AI-900 Certification - Semana 5, D√≠a 3

## Prompts y Tokens

**Fecha:** Mi√©rcoles, Semana 5  
**Duraci√≥n estimada:** 45-60 minutos  
**Nivel:** Fundamental

---

## üìã Objetivos del d√≠a

- Comprender qu√© son los tokens y c√≥mo funcionan
- Aprender t√©cnicas efectivas de prompt engineering
- Conocer estrategias para optimizar el uso de tokens
- Entender el concepto de context window
- Dominar los elementos de un buen prompt

---

## 1. ¬øQu√© son los Tokens?

### Definici√≥n

Los **tokens** son las unidades b√°sicas de procesamiento de texto en los modelos de lenguaje. Un token puede ser:
- Una palabra completa
- Parte de una palabra
- Un car√°cter especial
- Espacios y puntuaci√≥n

### ¬øC√≥mo funciona la tokenizaci√≥n?

Los modelos no procesan texto directamente, sino que lo dividen en tokens primero.

**Ejemplos de tokenizaci√≥n:**

```
Texto: "Hola mundo"
Tokens: ["Hola", " mundo"]
Total: 2 tokens

Texto: "OpenAI es incre√≠ble"
Tokens: ["Open", "AI", " es", " incre", "√≠ble"]
Total: 5 tokens

Texto: "¬°Fant√°stico!"
Tokens: ["¬°", "Fant", "√°st", "ico", "!"]
Total: 5 tokens

Texto: "AI-900"
Tokens: ["AI", "-", "900"]
Total: 3 tokens
```

### Reglas generales de tokenizaci√≥n

**Para ingl√©s:**
- ~1 token ‚âà 4 caracteres
- ~1 token ‚âà 0.75 palabras
- ~100 tokens ‚âà 75 palabras

**Para espa√±ol:**
- ~1 token ‚âà 3-4 caracteres
- ~1 token ‚âà 0.65 palabras
- ~100 tokens ‚âà 65 palabras

**Nota:** El espa√±ol y otros idiomas no ingleses tienden a usar m√°s tokens por palabra debido a:
- Acentos y caracteres especiales
- Palabras m√°s largas
- Menor representaci√≥n en datos de entrenamiento

### ¬øPor qu√© importan los tokens?

1. **L√≠mites del modelo**: Cada modelo tiene un l√≠mite m√°ximo de tokens (context window)
2. **Costos**: Se cobra por token procesado (input + output)
3. **Rendimiento**: M√°s tokens = m√°s tiempo de procesamiento

### Herramientas para contar tokens

**OpenAI Tokenizer:**
- https://platform.openai.com/tokenizer
- Permite ver exactamente c√≥mo se tokeniza tu texto

**Ejemplo pr√°ctico:**
```
Entrada: "Azure OpenAI Service es una plataforma empresarial"
Vista tokenizada: ["Azure", " Open", "AI", " Service", " es", " una", " plat", "aforma", " empres", "arial"]
Total tokens: 10
```

---

## 2. Context Window (Ventana de Contexto)

### Definici√≥n

El **context window** es la cantidad m√°xima de tokens que un modelo puede procesar en una sola solicitud (prompt + respuesta).

### L√≠mites por modelo

| Modelo | Context Window | Aproximado en palabras |
|--------|----------------|------------------------|
| GPT-3.5-turbo | 4,096 tokens | ~3,000 palabras |
| GPT-3.5-turbo-16k | 16,384 tokens | ~12,000 palabras |
| GPT-4 | 8,192 tokens | ~6,000 palabras |
| GPT-4-32k | 32,768 tokens | ~24,000 palabras |
| GPT-4-turbo | 128,000 tokens | ~96,000 palabras |
| GPT-5 (ChatGPT) | 256,000 tokens | ~190,000 palabras |
| GPT-5 (API) | 400,000 tokens | ~300,000 palabras |

### Distribuci√≥n de tokens

El context window se comparte entre:
- **Prompt tokens** (tu entrada)
- **Completion tokens** (respuesta del modelo)

**Ejemplo:**
```
Context window: 4,096 tokens
Prompt: 500 tokens
Max respuesta disponible: 3,596 tokens
```

### ¬øQu√© pasa si excedes el l√≠mite?

El modelo:
1. Trunca (corta) el texto que excede
2. Retorna un error indicando l√≠mite excedido
3. En conversaciones largas, olvida mensajes antiguos

**Estrategias si excedes:**
- Resumir informaci√≥n previa
- Dividir el contenido en m√∫ltiples solicitudes
- Usar un modelo con mayor context window
- Implementar t√©cnicas de chunking (dividir documentos)

---

## 3. Prompt Engineering Fundamentals

### ¬øQu√© es Prompt Engineering?

El **prompt engineering** es el arte y ciencia de dise√±ar instrucciones efectivas para obtener los mejores resultados de un modelo de IA.

### Anatom√≠a de un buen prompt

**Componentes principales:**

1. **Instrucci√≥n** (obligatorio): Qu√© quieres que haga
2. **Contexto** (opcional): Informaci√≥n de fondo
3. **Datos de entrada** (opcional): Informaci√≥n espec√≠fica a procesar
4. **Formato de salida** (opcional): C√≥mo quieres la respuesta

**Ejemplo estructurado:**
```
[INSTRUCCI√ìN]
Act√∫a como un experto en marketing digital.

[CONTEXTO]
Nuestra empresa vende software de gesti√≥n de proyectos para equipos remotos.

[DATOS DE ENTRADA]
Producto: TaskFlow Pro
Precio: $29/mes
Caracter√≠sticas principales: Colaboraci√≥n en tiempo real, reportes autom√°ticos, integraciones

[FORMATO DE SALIDA]
Genera 3 tweets promocionales, cada uno de m√°ximo 280 caracteres.
```

---

## 4. T√©cnicas de Prompt Engineering

### 1. Zero-Shot Prompting

**Descripci√≥n**: Dar la instrucci√≥n directamente sin ejemplos.

**Cu√°ndo usar**: Tareas simples y directas.

**Ejemplo:**
```
Prompt: "Clasifica el siguiente texto como positivo, negativo o neutral: 
'El servicio al cliente fue excelente y respondieron r√°pidamente.'"

Respuesta: "Positivo"
```

### 2. Few-Shot Prompting (Con ejemplos)

**Descripci√≥n**: Proporcionar ejemplos antes de la tarea real.

**Cu√°ndo usar**: Tareas espec√≠ficas o formatos particulares.

**Ejemplo:**
```
Prompt: 
"Clasifica los sentimientos de los siguientes textos:

Texto: 'Me encanta este producto'
Sentimiento: Positivo

Texto: 'Terrible experiencia, nunca volver√©'
Sentimiento: Negativo

Texto: 'El paquete lleg√≥ en la fecha estimada'
Sentimiento: Neutral

Texto: 'El servicio super√≥ mis expectativas'
Sentimiento:"

Respuesta: "Positivo"
```

### 3. Chain-of-Thought (Cadena de Pensamiento)

**Descripci√≥n**: Pedir al modelo que explique su razonamiento paso a paso.

**Cu√°ndo usar**: Problemas complejos, matem√°ticas, l√≥gica.

**Ejemplo:**
```
Prompt: 
"Un tren viaja 120 km en 2 horas. ¬øCu√°nto tiempo tardar√° en recorrer 300 km a la misma velocidad?

Piensa paso a paso:"

Respuesta esperada:
"Paso 1: Calcular la velocidad del tren
Velocidad = 120 km / 2 horas = 60 km/h

Paso 2: Calcular el tiempo para 300 km
Tiempo = 300 km / 60 km/h = 5 horas

Respuesta: 5 horas"
```

### 4. Role Prompting (Asignaci√≥n de Rol)

**Descripci√≥n**: Asignar un rol o personalidad espec√≠fica al modelo.

**Cu√°ndo usar**: Para respuestas con expertise o tono espec√≠fico.

**Ejemplo:**
```
Prompt: 
"Act√∫a como un pediatra con 20 a√±os de experiencia. 
Explica de manera comprensible para padres primerizos qu√© es la fiebre y cu√°ndo deben preocuparse."
```

### 5. Instruction Following (Seguimiento de Instrucciones)

**Descripci√≥n**: Dar instrucciones claras, espec√≠ficas y numeradas.

**Cu√°ndo usar**: Tareas multi-paso o con requisitos espec√≠ficos.

**Ejemplo:**
```
Prompt:
"Analiza el siguiente email y realiza estas tareas:
1. Identifica el remitente y el asunto
2. Resume el contenido en m√°ximo 2 oraciones
3. Clasifica la urgencia como: Alta, Media o Baja
4. Sugiere una acci√≥n de seguimiento

[Email aqu√≠]"
```

### 6. Constrained Output (Salida Restringida)

**Descripci√≥n**: Limitar el formato o contenido de la respuesta.

**Cu√°ndo usar**: Cuando necesitas formato espec√≠fico (JSON, tabla, lista).

**Ejemplo:**
```
Prompt:
"Extrae la siguiente informaci√≥n del texto y devu√©lvela SOLO en formato JSON:
- nombre
- edad
- ciudad

Texto: 'Juan P√©rez tiene 32 a√±os y vive en Madrid.'

Responde √öNICAMENTE con el JSON, sin texto adicional."

Respuesta esperada:
{
  "nombre": "Juan P√©rez",
  "edad": 32,
  "ciudad": "Madrid"
}
```

---

## 5. Mejores Pr√°cticas de Prompt Engineering

### ‚úÖ DO (Hacer)

**1. Ser espec√≠fico y claro**
```
‚ùå Malo: "H√°blame de Azure"
‚úÖ Bueno: "Explica en 3 p√°rrafos qu√© es Azure OpenAI Service y sus principales beneficios para empresas"
```

**2. Usar delimitadores para separar secciones**
```
Usa """ para el texto a analizar:
"""
[Texto aqu√≠]
"""

Usa ### para instrucciones especiales:
###
Responde en espa√±ol formal
###
```

**3. Especificar el formato de salida**
```
‚úÖ "Responde en formato de lista numerada"
‚úÖ "Genera una tabla con columnas: Nombre, Precio, Caracter√≠sticas"
‚úÖ "Devuelve solo JSON v√°lido, sin explicaciones adicionales"
```

**4. Dar ejemplos (few-shot)**
```
‚úÖ Proporciona 2-3 ejemplos del formato deseado
‚úÖ Muestra el patr√≥n que quieres que siga
```

**5. Dividir tareas complejas**
```
‚úÖ En lugar de: "Analiza, resume, traduce y formatea este documento"
‚úÖ Mejor: Hacer en pasos separados:
   1. Primero analizar
   2. Luego resumir
   3. Despu√©s traducir
   4. Finalmente formatear
```

**6. Usar "Piensa paso a paso" para razonamiento**
```
‚úÖ "Resuelve este problema matem√°tico. Piensa paso a paso y muestra tu razonamiento."
```

### ‚ùå DON'T (Evitar)

**1. Ser vago o ambiguo**
```
‚ùå "Dame informaci√≥n"
‚ùå "Ay√∫dame con esto"
‚ùå "¬øQu√© opinas?"
```

**2. Asumir conocimiento de contexto**
```
‚ùå "Contin√∫a con lo anterior" (sin proporcionar contexto)
‚ùå "Como mencion√© antes..." (en nueva conversaci√≥n)
```

**3. Instrucciones contradictorias**
```
‚ùå "S√© breve pero proporciona todos los detalles posibles"
‚ùå "Usa lenguaje t√©cnico pero expl√≠calo para principiantes"
```

**4. Prompts excesivamente largos sin estructura**
```
‚ùå Un p√°rrafo gigante de 500 palabras sin organizaci√≥n
‚úÖ Usar secciones claras con encabezados
```

---

## 6. Optimizaci√≥n de Tokens

### Estrategias para reducir uso de tokens

#### 1. Ser conciso en instrucciones
```
‚ùå (15 tokens): "Me gustar√≠a que por favor me ayudaras a generar un resumen de este texto"
‚úÖ (7 tokens): "Resume este texto:"
```

#### 2. Evitar repeticiones
```
‚ùå Repetir el mismo contexto en cada mensaje de la conversaci√≥n
‚úÖ Proporcionar contexto una vez, referenciar despu√©s
```

#### 3. Usar abreviaciones cuando sea apropiado
```
Original: "Microsoft Azure OpenAI Service" (6 tokens)
Abreviado: "Azure OpenAI" (3 tokens)
```

#### 4. Limitar max_tokens en la respuesta
```python
{
  "max_tokens": 150,  # Limita la longitud de respuesta
  "temperature": 0.7
}
```

#### 5. Resumir conversaciones largas
```
En lugar de mantener 50 mensajes en el historial:
‚úÖ Resumir mensajes antiguos cada 10-15 intercambios
‚úÖ Mantener solo el resumen + √∫ltimos 5 mensajes
```

### C√°lculo de costos basado en tokens

**Ejemplo con GPT-4:**
- Precio: $0.03 / 1K prompt tokens
- Precio: $0.06 / 1K completion tokens

**Escenario:**
```
Prompt: 500 tokens
Respuesta: 300 tokens

Costo:
- Prompt: (500/1000) √ó $0.03 = $0.015
- Completion: (300/1000) √ó $0.06 = $0.018
- Total: $0.033 por llamada

Con 1,000 llamadas/d√≠a:
$0.033 √ó 1,000 = $33/d√≠a = ~$1,000/mes
```

**Optimizaci√≥n:**
```
Reducir prompt a 300 tokens (-40%)
Limitar respuesta a 200 tokens (-33%)

Nuevo costo:
- Prompt: (300/1000) √ó $0.03 = $0.009
- Completion: (200/1000) √ó $0.06 = $0.012
- Total: $0.021 por llamada

Con 1,000 llamadas/d√≠a:
$0.021 √ó 1,000 = $21/d√≠a = ~$630/mes

Ahorro: $370/mes (37%)
```

---

## 7. Casos de Uso Pr√°cticos

### Caso 1: Extracci√≥n de Informaci√≥n

**Objetivo**: Extraer datos estructurados de texto libre.

**Prompt optimizado:**
```
Extrae la siguiente informaci√≥n del email y devuelve solo JSON:
- remitente
- fecha
- asunto
- prioridad (Alta/Media/Baja)

Email:
"""
De: maria.lopez@empresa.com
Fecha: 2025-12-03
Asunto: URGENTE - Sistema ca√≠do

El servidor principal no responde desde las 09:00 AM.
"""

JSON:
```

**Tokens aproximados**: 60 tokens (prompt) + 30 tokens (respuesta) = 90 tokens

---

### Caso 2: Clasificaci√≥n de Sentimientos

**Objetivo**: Clasificar reviews de productos.

**Prompt optimizado:**
```
Clasifica estos reviews (Positivo/Negativo/Neutral):

1. "Excelente producto, super√≥ expectativas" ‚Üí
2. "No funciona como esperaba" ‚Üí
3. "Entrega puntual, producto correcto" ‚Üí
```

**Tokens aproximados**: 35 tokens (prompt) + 10 tokens (respuesta) = 45 tokens

---

### Caso 3: Generaci√≥n de C√≥digo

**Objetivo**: Crear funci√≥n Python espec√≠fica.

**Prompt optimizado:**
```
Crea una funci√≥n Python que:
1. Reciba una lista de n√∫meros
2. Retorne la mediana
3. Maneje lista vac√≠a

Solo c√≥digo, sin explicaciones.
```

**Tokens aproximados**: 30 tokens (prompt) + 80 tokens (respuesta) = 110 tokens

---

### Caso 4: Resumen de Documentos

**Objetivo**: Resumir documento largo.

**Prompt optimizado:**
```
Resume en 3 puntos clave:
"""
[Documento aqu√≠ - 2000 tokens]
"""

Formato:
1. [Punto clave 1]
2. [Punto clave 2]
3. [Punto clave 3]
```

**Tokens aproximados**: 2,050 tokens (prompt) + 50 tokens (respuesta) = 2,100 tokens

---

## 8. T√©cnicas Avanzadas

### System Message vs User Message

**System Message**: Define comportamiento global
```json
{
  "role": "system",
  "content": "Eres un asistente de programaci√≥n experto en Python. Siempre proporcionas c√≥digo limpio y comentado."
}
```

**User Message**: La solicitud espec√≠fica
```json
{
  "role": "user",
  "content": "Crea una funci√≥n para calcular factorial"
}
```

**Ventaja**: El system message se procesa una vez, ahorrando tokens en conversaciones largas.

---

### Prompt Chaining (Encadenamiento)

**Concepto**: Dividir tarea compleja en pasos secuenciales.

**Ejemplo:**
```
Paso 1: "Extrae los nombres de todos los clientes mencionados"
Paso 2: "Para cada cliente, identifica sus compras"
Paso 3: "Calcula el total gastado por cada cliente"
Paso 4: "Genera reporte en formato tabla"
```

**Beneficios:**
- M√°s preciso que un prompt gigante
- Permite verificar cada paso
- Reduce uso de tokens al enfocarse en una tarea a la vez

---

### Retrieval-Augmented Generation (RAG)

**Concepto**: Combinar b√∫squeda de informaci√≥n con generaci√≥n.

**Flujo:**
```
1. Usuario hace pregunta
2. Buscar informaci√≥n relevante en base de datos (embeddings)
3. Incluir solo informaci√≥n relevante en el prompt
4. Generar respuesta basada en esa informaci√≥n

Beneficio: Reduce tokens al incluir solo lo necesario
```

---

## ‚úÖ Puntos Clave para el Examen

- **Tokens** son unidades b√°sicas de procesamiento (~4 caracteres en ingl√©s, ~3-4 en espa√±ol)
- **Context window** es el l√≠mite m√°ximo de tokens (prompt + respuesta)
- GPT-5 tiene el context window m√°s grande (256K-400K tokens)
- **Prompt engineering** es dise√±ar instrucciones efectivas para mejores resultados
- T√©cnicas principales: Zero-shot, Few-shot, Chain-of-Thought, Role Prompting
- **System message** define comportamiento global del asistente
- **Few-shot prompting** proporciona ejemplos para mejorar resultados
- **Delimitadores** (""", ###, ---) ayudan a estructurar prompts
- Optimizar tokens reduce costos: ser conciso, evitar repeticiones, limitar max_tokens
- **Chain-of-Thought** mejora razonamiento en problemas complejos
- Especificar formato de salida (JSON, tabla, lista) para respuestas estructuradas
- Los costos se calculan por: (prompt tokens + completion tokens) √ó precio por token

---

## üéØ Preguntas Estilo Examen Microsoft AI-900

### Pregunta 1
Est√°s usando GPT-4 con un context window de 8,192 tokens. Tu prompt usa 7,000 tokens. ¬øCu√°ntos tokens tiene disponibles el modelo para la respuesta?

- [ ] A) 8,192 tokens  
- [ ] B) 7,000 tokens  
- [-] C) 1,192 tokens  
- [ ] D) 15,192 tokens

**Respuesta correcta: C) 1,192 tokens**

**Explicaci√≥n**: El **context window** se comparte entre el prompt y la respuesta. Si el context window es 8,192 tokens y el prompt usa 7,000 tokens, quedan 8,192 - 7,000 = 1,192 tokens disponibles para la respuesta del modelo. No se suman (D es incorrecto), y las opciones A y B no consideran la resta necesaria.

---

### Pregunta 2
¬øCu√°l de las siguientes t√©cnicas de prompt engineering proporciona ejemplos al modelo antes de hacer la solicitud real?

- [ ] A) Zero-shot prompting  
- [-] B) Few-shot prompting  
- [ ] C) Chain-of-thought  
- [ ] D) Role prompting

**Respuesta correcta: B) Few-shot prompting**

**Explicaci√≥n**: **Few-shot prompting** consiste en proporcionar algunos ejemplos (t√≠picamente 2-5) antes de la tarea real para que el modelo entienda el patr√≥n deseado. Zero-shot (A) no usa ejemplos, Chain-of-thought (C) enfoca en razonamiento paso a paso, y Role prompting (D) asigna un rol o personalidad.

---

### Pregunta 3
Necesitas que el modelo explique su razonamiento paso a paso para resolver un problema matem√°tico complejo. ¬øQu√© t√©cnica deber√≠as usar?

- [ ] A) Few-shot prompting  
- [ ] B) Zero-shot prompting  
- [-] C) Chain-of-thought prompting  
- [ ] D) Constrained output

**Respuesta correcta: C) Chain-of-thought prompting**

**Explicaci√≥n**: **Chain-of-thought (cadena de pensamiento)** es espec√≠ficamente para obtener razonamiento paso a paso, ideal para matem√°ticas, l√≥gica y problemas complejos. T√≠picamente se activa con frases como "piensa paso a paso" o "explica tu razonamiento". Few-shot (A) usa ejemplos, Zero-shot (B) es directo, y Constrained output (D) limita el formato de salida.

---

### Pregunta 4
¬øQu√© rol de mensaje debes usar para definir el comportamiento general y la personalidad del asistente en una conversaci√≥n?

- [ ] A) user  
- [ ] B) assistant  
- [-] C) system  
- [ ] D) function

**Respuesta correcta: C) system**

**Explicaci√≥n**: El mensaje con rol **system** define el comportamiento global, personalidad y reglas que el asistente debe seguir durante toda la conversaci√≥n (ej: "Eres un experto en medicina"). El rol **user** es para mensajes del usuario, **assistant** para respuestas previas del modelo, y **function** para llamadas a funciones externas.

---

### Pregunta 5
Aproximadamente, ¬øcu√°ntos caracteres equivalen a un token en ingl√©s?

- [ ] A) 1 car√°cter  
- [-] B) 4 caracteres  
- [ ] C) 10 caracteres  
- [ ] D) 20 caracteres

**Respuesta correcta: B) 4 caracteres**

**Explicaci√≥n**: En ingl√©s, la regla general es que **1 token ‚âà 4 caracteres** o aproximadamente 0.75 palabras. Esta es una estimaci√≥n √∫til para calcular tokens. En espa√±ol y otros idiomas puede ser ligeramente diferente (3-4 caracteres por token) debido a acentos y estructura del idioma.

---

## üìñ Recursos Adicionales

- [OpenAI Tokenizer](https://platform.openai.com/tokenizer)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [Azure OpenAI Best Practices](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/best-practices)
- [OpenAI Prompt Engineering Documentation](https://platform.openai.com/docs/guides/prompt-engineering)
