# ğŸ“š SEMANA 2 - MACHINE LEARNING EN PROFUNDIDAD

---

## ğŸ“– MARTES 11 NOV (1.5 horas) - RegresiÃ³n y sus mÃ©tricas

### ğŸ¯ Objetivo del dÃ­a

Entender quÃ© es regresiÃ³n en profundidad y cÃ³mo evaluar si un modelo de regresiÃ³n es bueno

---

## ğŸ”„ REPASO RÃPIDO: Â¿QuÃ© es RegresiÃ³n?

**Del Lunes aprendiste:**

- âœ… RegresiÃ³n = predecir NÃšMEROS continuos
- âœ… Responde "Â¿CuÃ¡nto?" o "Â¿QuÃ© valor?"
- âœ… Ejemplos: precio, temperatura, ventas, edad, tiempo

**Hoy profundizaremos en:**

- CÃ³mo funciona realmente la regresiÃ³n
- CÃ³mo saber si tu modelo es bueno
- MÃ©tricas para evaluar modelos de regresiÃ³n

---

## ğŸ“ˆ Â¿CÃ“MO FUNCIONA LA REGRESIÃ“N?

### ğŸ’¡ Concepto fundamental: Encontrar la relaciÃ³n

**La regresiÃ³n busca la RELACIÃ“N entre:**

- **Variables de entrada (features/caracterÃ­sticas):** Los datos que tienes
- **Variable de salida (target/objetivo):** El nÃºmero que quieres predecir

**AnalogÃ­a:**
Como encontrar la fÃ³rmula que conecta causa â†’ efecto

- TamaÃ±o de casa (causa) â†’ Precio (efecto)
- Horas de estudio (causa) â†’ Nota del examen (efecto)

---

### ğŸ“Š REGRESIÃ“N LINEAL (el tipo mÃ¡s simple)

**Concepto:** Encontrar una **lÃ­nea recta** que mejor representa los datos

#### Ejemplo visual (imagina este grÃ¡fico):

```
Precio ($)
â†‘
|                                    â€¢
|                              â€¢
|                        â€¢
|                  â€¢
|            â€¢
|      â€¢
|â€¢
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ TamaÃ±o (mÂ²)
     LÃ­nea de regresiÃ³n: y = mx + b
```

**La lÃ­nea representa:**

- `y` = precio (lo que queremos predecir)
- `x` = tamaÃ±o (lo que sabemos)
- `m` = pendiente (cuÃ¡nto sube el precio por cada mÂ² adicional)
- `b` = intersecciÃ³n (precio base)

**Ejemplo concreto:**

```
Precio = 1,000â‚¬ * TamaÃ±o + 50,000â‚¬
         â†‘                 â†‘
      Por cada mÂ²    Precio base

Si casa tiene 100mÂ²:
Precio = 1,000 * 100 + 50,000 = 150,000â‚¬
```

---

### ğŸ¯ El objetivo: Minimizar el ERROR

**Â¿QuÃ© es el error?**
La diferencia entre:

- Lo que el modelo PREDIJO
- Lo que REALMENTE era

**Ejemplo:**

- Precio real de casa: 152,000â‚¬
- Precio predicho: 150,000â‚¬
- Error: 2,000â‚¬

**El modelo busca:** Ajustar la lÃ­nea para que los errores sean lo mÃ¡s pequeÃ±os posible

---

## ğŸ“ MÃ‰TRICAS DE REGRESIÃ“N: Â¿Es bueno mi modelo?

**Pregunta clave:** "EntrenÃ© un modelo de regresiÃ³n. Â¿CÃ³mo sÃ© si funciona bien?"

**Respuesta:** Usas MÃ‰TRICAS de evaluaciÃ³n

### ğŸ¯ Las 3 mÃ©tricas principales:

```
MÃ‰TRICAS DE REGRESIÃ“N
â”‚
â”œâ”€â”€ MAE (Mean Absolute Error) - Error Absoluto Medio
â”œâ”€â”€ RMSE (Root Mean Square Error) - RaÃ­z del Error CuadrÃ¡tico Medio
â””â”€â”€ RÂ² (R-squared) - Coeficiente de DeterminaciÃ³n
```

---

## 1ï¸âƒ£ MAE (Mean Absolute Error)

### ğŸ“Š Â¿QuÃ© mide?

**El error promedio en las mismas unidades que tu predicciÃ³n.**

**FÃ³rmula en palabras:**

```
MAE = Promedio de |Valor Real - Valor Predicho|
```

**El sÃ­mbolo | | significa "valor absoluto" (ignorar si es positivo o negativo)**

---

### ğŸ’¡ Ejemplo prÃ¡ctico:

**Predijiste precios de 5 casas:**

| Casa | Precio Real | Precio Predicho | Error   | Error Absoluto |
| ---- | ----------- | --------------- | ------- | -------------- |
| 1    | 150,000â‚¬    | 148,000â‚¬        | +2,000â‚¬ | 2,000â‚¬         |
| 2    | 200,000â‚¬    | 205,000â‚¬        | -5,000â‚¬ | 5,000â‚¬         |
| 3    | 180,000â‚¬    | 178,000â‚¬        | +2,000â‚¬ | 2,000â‚¬         |
| 4    | 220,000â‚¬    | 215,000â‚¬        | +5,000â‚¬ | 5,000â‚¬         |
| 5    | 190,000â‚¬    | 192,000â‚¬        | -2,000â‚¬ | 2,000â‚¬         |

**CÃ¡lculo del MAE:**

```
MAE = (2,000 + 5,000 + 2,000 + 5,000 + 2,000) / 5
MAE = 16,000 / 5
MAE = 3,200â‚¬
```

**InterpretaciÃ³n:**
"En promedio, mis predicciones se equivocan por 3,200â‚¬"

---

### âœ… Ventajas del MAE:

âœ… **FÃ¡cil de entender:** EstÃ¡ en las mismas unidades (euros, metros, dÃ­as)
âœ… **Interpretable:** "Me equivoco en promedio por X"
âœ… **No se afecta tanto por valores extremos (outliers)**

### âš ï¸ Limitaciones del MAE:

âš ï¸ Trata todos los errores igual (un error de 10â‚¬ = diez errores de 1â‚¬)
âš ï¸ No "castiga" errores grandes mÃ¡s que errores pequeÃ±os

---

## 2ï¸âƒ£ RMSE (Root Mean Square Error)

### ğŸ“Š Â¿QuÃ© mide?

**Similar al MAE, pero "castiga" mÃ¡s los errores grandes.**

**FÃ³rmula en palabras:**

```
1. Calcula el error para cada predicciÃ³n
2. Eleva cada error al cuadrado (esto amplifica errores grandes)
3. Saca el promedio de esos cuadrados
4. Saca la raÃ­z cuadrada del promedio
```

**Â¿Por quÃ© elevar al cuadrado?**

- Un error de 10 al cuadrado = 100
- Dos errores de 5 al cuadrado = 25 + 25 = 50
- Â¡Prefiere muchos errores pequeÃ±os que un error grande!

---

### ğŸ’¡ Ejemplo prÃ¡ctico (mismos datos):

| Casa | Precio Real | Precio Predicho | Error  | ErrorÂ²     |
| ---- | ----------- | --------------- | ------ | ---------- |
| 1    | 150,000â‚¬    | 148,000â‚¬        | 2,000â‚¬ | 4,000,000  |
| 2    | 200,000â‚¬    | 205,000â‚¬        | 5,000â‚¬ | 25,000,000 |
| 3    | 180,000â‚¬    | 178,000â‚¬        | 2,000â‚¬ | 4,000,000  |
| 4    | 220,000â‚¬    | 215,000â‚¬        | 5,000â‚¬ | 25,000,000 |
| 5    | 190,000â‚¬    | 192,000â‚¬        | 2,000â‚¬ | 4,000,000  |

**CÃ¡lculo del RMSE:**

```
Suma de erroresÂ² = 4M + 25M + 4M + 25M + 4M = 62,000,000
Promedio = 62,000,000 / 5 = 12,400,000
RMSE = âˆš12,400,000 â‰ˆ 3,521â‚¬
```

**InterpretaciÃ³n:**
"En promedio (penalizando errores grandes), me equivoco por 3,521â‚¬"

---

### âœ… Ventajas del RMSE:

âœ… **Penaliza errores grandes:** Ãštil cuando errores grandes son MUY malos
âœ… **Mismas unidades** que el objetivo (euros, metros, etc.)
âœ… **MÃ¡s usado en competencias de ML**

### âš ï¸ Limitaciones del RMSE:

âš ï¸ MÃ¡s difÃ­cil de interpretar que MAE
âš ï¸ Muy sensible a outliers (valores extremos)
âš ï¸ Siempre serÃ¡ â‰¥ MAE (por diseÃ±o)

---

### ğŸ” MAE vs RMSE: Â¿CuÃ¡l usar?

| SituaciÃ³n                         | Usa  | Por quÃ©                           |
| --------------------------------- | ---- | --------------------------------- |
| Errores grandes son CRÃTICOS      | RMSE | Penaliza mÃ¡s los errores grandes  |
| Quieres mÃ©trica fÃ¡cil de explicar | MAE  | MÃ¡s interpretable                 |
| Tienes muchos outliers en datos   | MAE  | Menos sensible a valores extremos |
| EstÃ¡ndar de la industria          | RMSE | MÃ¡s comÃºn en competencias         |

**Para el examen AI-900:**

- âœ… Conoce QUÃ‰ miden ambas
- âœ… Sabe que ambas miden error promedio
- âœ… RMSE penaliza errores grandes mÃ¡s
- âŒ NO necesitas calcularlas manualmente

---

## 3ï¸âƒ£ RÂ² (R-squared) - Coeficiente de DeterminaciÃ³n

### ğŸ“Š Â¿QuÃ© mide?

**"Â¿QuÃ© tan bien el modelo explica la variabilidad de los datos?"**

**Rango de valores: 0 a 1 (a veces puede ser negativo si el modelo es muy malo)**

- **RÂ² = 1.0** (100%) â†’ Modelo PERFECTO, predice TODO correctamente
- **RÂ² = 0.8** (80%) â†’ Modelo explica 80% de la variabilidad
- **RÂ² = 0.5** (50%) â†’ Modelo explica solo 50%
- **RÂ² = 0.0** (0%) â†’ Modelo no explica nada (tan malo como predecir el promedio)
- **RÂ² < 0** â†’ Modelo PEOR que predecir el promedio

---

### ğŸ’¡ InterpretaciÃ³n intuitiva:

**Imagina que:**

- Tienes datos de precios de casas: 100k, 150k, 200k, 250k
- La variabilidad (cuÃ¡nto varÃ­an) es grande

**Tres escenarios:**

**1. Sin modelo (solo promedio):**

```
Predigo 175k para TODAS las casas
RÂ² = 0 (no explico la variabilidad)
```

**2. Modelo malo:**

```
Mis predicciones varÃ­an un poco: 160k, 170k, 180k, 190k
RÂ² = 0.3 (explico 30% de la variabilidad)
```

**3. Modelo bueno:**

```
Mis predicciones: 105k, 152k, 198k, 247k
RÂ² = 0.95 (explico 95% de la variabilidad)
```

---

### ğŸ“Š Â¿QuÃ© es un buen RÂ²?

**Depende del dominio, pero en general:**

| RÂ²            | InterpretaciÃ³n   | Calidad    |
| ------------- | ---------------- | ---------- |
| **0.9 - 1.0** | Excelente modelo | â­â­â­â­â­ |
| **0.7 - 0.9** | Buen modelo      | â­â­â­â­   |
| **0.5 - 0.7** | Modelo moderado  | â­â­â­     |
| **0.3 - 0.5** | Modelo dÃ©bil     | â­â­       |
| **< 0.3**     | Modelo muy dÃ©bil | â­         |
| **< 0**       | Modelo horrible  | ğŸ’€         |

**IMPORTANTE:**

- En ciencias sociales: RÂ² = 0.5 puede ser bueno
- En fÃ­sica/ingenierÃ­a: RÂ² = 0.9 es el mÃ­nimo esperado
- En finanzas: RÂ² = 0.3 puede ser Ãºtil

---

### âœ… Ventajas del RÂ²:

âœ… **Sin unidades:** Siempre entre 0 y 1, fÃ¡cil de comparar
âœ… **Intuitivo:** Porcentaje de variabilidad explicada
âœ… **EstÃ¡ndar de la industria**

### âš ï¸ Limitaciones del RÂ²:

âš ï¸ Puede ser engaÃ±oso con datos pequeÃ±os
âš ï¸ No indica el tamaÃ±o del error (solo "fit")
âš ï¸ Puede mejorar artificialmente aÃ±adiendo mÃ¡s features

---

## ğŸ“Š TABLA COMPARATIVA: Las 3 mÃ©tricas

| MÃ©trica  | Â¿QuÃ© mide?                        | Rango  | Mejor valor  | Unidades            | InterpretaciÃ³n                  |
| -------- | --------------------------------- | ------ | ------------ | ------------------- | ------------------------------- |
| **MAE**  | Error promedio                    | 0 a âˆ  | 0 (perfecto) | Mismas que objetivo | "Me equivoco en promedio por X" |
| **RMSE** | Error promedio (penaliza grandes) | 0 a âˆ  | 0 (perfecto) | Mismas que objetivo | "Error tÃ­pico es X"             |
| **RÂ²**   | Variabilidad explicada            | -âˆ a 1 | 1 (perfecto) | Sin unidades        | "Explico X% de los datos"       |

**Regla general:**

- MAE y RMSE: **MÃ¡s bajo = mejor**
- RÂ²: **MÃ¡s alto = mejor** (cercano a 1)

---

## ğŸ¯ EJEMPLO COMPLETO: Evaluar un modelo

### Caso: Predecir precio de casas

**Datos reales de 10 casas:**

| Casa | Precio Real | Precio Predicho | Error   |
| ---- | ----------- | --------------- | ------- |
| 1    | 150,000â‚¬    | 148,000â‚¬        | 2,000â‚¬  |
| 2    | 200,000â‚¬    | 205,000â‚¬        | -5,000â‚¬ |
| 3    | 180,000â‚¬    | 178,000â‚¬        | 2,000â‚¬  |
| 4    | 220,000â‚¬    | 215,000â‚¬        | 5,000â‚¬  |
| 5    | 190,000â‚¬    | 192,000â‚¬        | -2,000â‚¬ |
| 6    | 160,000â‚¬    | 158,000â‚¬        | 2,000â‚¬  |
| 7    | 210,000â‚¬    | 208,000â‚¬        | 2,000â‚¬  |
| 8    | 175,000â‚¬    | 180,000â‚¬        | -5,000â‚¬ |
| 9    | 195,000â‚¬    | 193,000â‚¬        | 2,000â‚¬  |
| 10   | 230,000â‚¬    | 225,000â‚¬        | 5,000â‚¬  |

**Resultados del modelo:**

- **MAE = 3,200â‚¬**
- **RMSE = 3,521â‚¬**
- **RÂ² = 0.92**

---

### ğŸ“‹ InterpretaciÃ³n:

**MAE = 3,200â‚¬**

- "En promedio, mis predicciones se desvÃ­an 3,200â‚¬ del precio real"
- En un mercado de casas de ~190,000â‚¬, un error de 3,200â‚¬ es apenas ~1.7%
- âœ… Bastante bueno

**RMSE = 3,521â‚¬**

- Un poco mÃ¡s alto que MAE (normal)
- Indica que hay algunos errores mÃ¡s grandes (las casas 2, 4, 8, 10)
- Pero no demasiado diferente del MAE â†’ no hay outliers extremos

**RÂ² = 0.92**

- El modelo explica 92% de la variabilidad en precios
- â­â­â­â­â­ Excelente modelo
- Solo 8% de la variabilidad no se explica

**ConclusiÃ³n:** Este es un modelo MUY BUENO para predecir precios de casas.

---

## ğŸ“ PREGUNTAS TIPO EXAMEN

### Pregunta 1:

**Has entrenado un modelo de regresiÃ³n para predecir ventas mensuales. El modelo tiene un RÂ² de 0.85. Â¿QuÃ© significa esto?**

A) El modelo se equivoca en promedio por 0.85 unidades
B) El modelo es 85% preciso
C) El modelo explica 85% de la variabilidad en las ventas âœ…
D) El modelo tiene 85% de probabilidad de ser correcto

**Por quÃ© C:** RÂ² mide quÃ© porcentaje de la variabilidad de los datos explica el modelo.

---

### Pregunta 2:

Tienes dos modelos de regresiÃ³n para predecir precios:

- Modelo A: MAE = 5,000â‚¬, RMSE = 5,200â‚¬
- Modelo B: MAE = 5,000â‚¬, RMSE = 8,000â‚¬

Â¿QuÃ© puedes concluir?

A) Ambos modelos son idÃ©nticos
B) Modelo B tiene errores mÃ¡s grandes y variables âœ…
C) Modelo A es peor que Modelo B
D) No se puede determinar cuÃ¡l es mejor

**Por quÃ© B:** Si RMSE es mucho mayor que MAE, significa que hay errores grandes (outliers) que estÃ¡n siendo penalizados. Modelo B tiene RMSE mucho mayor = errores mÃ¡s variables.

---

### Pregunta 3:

**Â¿CuÃ¡l de estas mÃ©tricas de regresiÃ³n penaliza MÃS los errores grandes?**

A) MAE
B) RMSE âœ…
C) RÂ²
D) Todas por igual

**Por quÃ© B:** RMSE eleva los errores al cuadrado antes de promediarlos, lo que penaliza errores grandes mÃ¡s que MAE.

---

### Pregunta 4:

**Un modelo de regresiÃ³n tiene RÂ² = -0.2. Â¿QuÃ© significa esto?**

A) El modelo es excelente
B) El modelo explica 20% de los datos
C) El modelo es peor que simplemente predecir el promedio âœ…
D) Hay un error en el cÃ¡lculo

**Por quÃ© C:** RÂ² negativo significa que el modelo es PEOR que un modelo bÃ¡sico que solo predice el promedio. Es un modelo muy malo.

---

### Pregunta 5:

**Â¿QuÃ© mÃ©trica de regresiÃ³n estÃ¡ en las mismas unidades que la variable objetivo?**

A) Solo MAE
B) Solo RMSE
C) MAE y RMSE âœ…
D) RÂ²

**Por quÃ© C:** Tanto MAE como RMSE estÃ¡n en las mismas unidades que lo que predices (euros, metros, dÃ­as). RÂ² no tiene unidades.

---

## ğŸ” CONCEPTOS ADICIONALES IMPORTANTES

### 1ï¸âƒ£ Overfitting (Sobreajuste)

**Â¿QuÃ© es?**
Cuando el modelo "memoriza" los datos de entrenamiento en lugar de aprender patrones generales.

**AnalogÃ­a:**
Como estudiar SOLO los exÃ¡menes anteriores con sus respuestas exactas, pero no entender los conceptos. Cuando viene un examen con preguntas diferentes, fallas.

**SÃ­ntomas:**

```
Datos de entrenamiento: RÂ² = 0.99 â­â­â­â­â­
Datos de prueba:        RÂ² = 0.45 â­â­

Â¡OVERFITTING! El modelo no generaliza bien.
```

**SoluciÃ³n:**

- MÃ¡s datos de entrenamiento
- Modelo mÃ¡s simple
- RegularizaciÃ³n (tÃ©cnicas avanzadas)
- ValidaciÃ³n cruzada

---

### 2ï¸âƒ£ Underfitting (Subajuste)

**Â¿QuÃ© es?**
Cuando el modelo es DEMASIADO simple y no captura los patrones de los datos.

**AnalogÃ­a:**
Como intentar dibujar un cÃ­rculo con solo una lÃ­nea recta. No importa cÃ³mo la dibujes, nunca capturarÃ¡s la forma.

**SÃ­ntomas:**

```
Datos de entrenamiento: RÂ² = 0.40 â­â­
Datos de prueba:        RÂ² = 0.38 â­â­

Mal en ambos â†’ UNDERFITTING
```

**SoluciÃ³n:**

- Modelo mÃ¡s complejo
- MÃ¡s features (caracterÃ­sticas)
- Mejor ingenierÃ­a de features

---

### 3ï¸âƒ£ El modelo ideal: Balance perfecto

**Lo que queremos:**

```
Datos de entrenamiento: RÂ² = 0.88 â­â­â­â­
Datos de prueba:        RÂ² = 0.85 â­â­â­â­

Â¡PERFECTO! Generaliza bien.
```

**Visual:**

```
     â”‚
 RÂ²  â”‚     Underfitting â”‚  Sweet Spot  â”‚ Overfitting
     â”‚                  â”‚              â”‚
1.0  â”‚                  â”‚     â­       â”‚    â€¢
     â”‚                  â”‚              â”‚   /
0.8  â”‚        â€¢         â”‚              â”‚  â€¢
     â”‚       /          â”‚     Train    â”‚
0.6  â”‚      â€¢           â”‚     Test     â”‚
     â”‚                  â”‚              â”‚
0.4  â”‚                  â”‚              â”‚  Test
     â”‚    Test=Train    â”‚              â”‚
     â”‚                  â”‚              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
          Muy simple   Complejidad   Muy complejo
```

---

### 4ï¸âƒ£ Train/Test Split

**Concepto crucial:**
NO evalÃºes tu modelo con los MISMOS datos con los que entrenaste.

**Proceso correcto:**

```
Datos totales: 1000 ejemplos
    â†“
Split (divisiÃ³n)
    â†“
â”œâ”€ Train (80%): 800 ejemplos â†’ Entrena el modelo
â””â”€ Test (20%):  200 ejemplos â†’ EvalÃºa el modelo
```

**Â¿Por quÃ©?**

- Train: El modelo aprende de estos
- Test: Simula datos "nuevos" que el modelo nunca vio
- EvalÃºas cÃ³mo generaliza a datos nuevos

**Split tÃ­pico:**

- 80/20 (80% train, 20% test)
- 70/30
- 60/20/20 (train/validation/test)

---

## âœ… TAREAS DE HOY (Martes)

### 1. Microsoft Learn (45 min)

**MÃ³dulos a completar:**

- **"CreaciÃ³n de modelos de regresiÃ³n"**
- **"Entrenamiento y evaluaciÃ³n de modelos de regresiÃ³n"**

Link: https://learn.microsoft.com/es-es/training/modules/train-evaluate-regression-models/

---

### 2. Ejercicio: Interpretar mÃ©tricas (20 min)

**Para cada escenario, evalÃºa el modelo:**

**Escenario 1:**
Predecir temperatura diaria (rango: -5Â°C a 35Â°C)

- MAE = 0.8Â°C
- RMSE = 1.1Â°C
- RÂ² = 0.94

Â¿Es un buen modelo? **\*\***\_\_\_**\*\***
Â¿Por quÃ©? **\*\***\_\_\_**\*\***

---

**Escenario 2:**
Predecir precio de acciones (rango: $50 - $500)

- MAE = $45
- RMSE = $80
- RÂ² = 0.35

Â¿Es un buen modelo? **\*\***\_\_\_**\*\***
Â¿Por quÃ©? **\*\***\_\_\_**\*\***

---

**Escenario 3:**
Predecir dÃ­as de hospitalizaciÃ³n (rango: 1-30 dÃ­as)

- MAE = 1.5 dÃ­as
- RMSE = 2.8 dÃ­as
- RÂ² = 0.75

Â¿Es un buen modelo? **\*\***\_\_\_**\*\***
Â¿RMSE mucho mayor que MAE indica quÃ©? **\*\***\_\_\_**\*\***

---

**Escenario 4:**
Modelo A vs Modelo B para predecir ventas:

Modelo A:

- MAE = 1,000 unidades
- RMSE = 1,200 unidades
- RÂ² = 0.82

Modelo B:

- MAE = 1,200 unidades
- RMSE = 1,250 unidades
- RÂ² = 0.85

Â¿CuÃ¡l elegirÃ­as y por quÃ©? **\*\***\_\_\_**\*\***

---

**Escenario 5:**
Entrenaste un modelo para predecir ingresos anuales:

- Train RÂ² = 0.98
- Test RÂ² = 0.52

Â¿QuÃ© problema tiene el modelo? **\*\***\_\_\_**\*\***
Â¿CÃ³mo lo solucionarÃ­as? **\*\***\_\_\_**\*\***

---

### 3. Crea Flashcards (15 min)

**Crea estas 12 tarjetas:**

**Tarjeta 1:**

- Frente: "Â¿QuÃ© mide MAE?"
- AtrÃ¡s: "Error promedio en las mismas unidades que el objetivo. FÃ¡cil de interpretar."

**Tarjeta 2:**

- Frente: "Â¿QuÃ© mide RMSE?"
- AtrÃ¡s: "Error promedio pero penalizando errores grandes mÃ¡s. Siempre â‰¥ MAE."

**Tarjeta 3:**

- Frente: "Â¿QuÃ© mide RÂ²?"
- AtrÃ¡s: "QuÃ© porcentaje de la variabilidad de los datos explica el modelo. Rango: 0 a 1."

**Tarjeta 4:**

- Frente: "Â¿CuÃ¡l es mejor: MAE alto o bajo?"
- AtrÃ¡s: "BAJO. MAE mide error, menor error = mejor modelo."

**Tarjeta 5:**

- Frente: "Â¿CuÃ¡l es mejor: RÂ² alto o bajo?"
- AtrÃ¡s: "ALTO. RÂ² cerca de 1 = modelo explica casi toda la variabilidad."

**Tarjeta 6:**

- Frente: "Â¿QuÃ© significa RÂ² = 0.85?"
- AtrÃ¡s: "El modelo explica 85% de la variabilidad en los datos. Modelo bueno/excelente."

**Tarjeta 7:**

- Frente: "Â¿QuÃ© significa RÂ² negativo?"
- AtrÃ¡s: "El modelo es PEOR que simplemente predecir el promedio. Modelo muy malo."

**Tarjeta 8:**

- Frente: "Â¿Por quÃ© RMSE > MAE?"
- AtrÃ¡s: "RMSE penaliza errores grandes mÃ¡s al elevar al cuadrado. Si RMSE >> MAE, hay outliers."

**Tarjeta 9:**

- Frente: "Â¿QuÃ© es overfitting?"
- AtrÃ¡s: "Cuando el modelo memoriza datos de entrenamiento pero no generaliza bien a datos nuevos."

**Tarjeta 10:**

- Frente: "SÃ­ntoma de overfitting"
- AtrÃ¡s: "Train RÂ² muy alto (0.99) pero Test RÂ² bajo (0.50). Gran diferencia entre train y test."

**Tarjeta 11:**

- Frente: "Â¿QuÃ© es el train/test split?"
- AtrÃ¡s: "Dividir datos en 2 grupos: uno para entrenar (80%) y otro para evaluar (20%) el modelo."

**Tarjeta 12:**

- Frente: "Â¿Por quÃ© necesitamos test set?"
- AtrÃ¡s: "Para evaluar cÃ³mo el modelo generaliza a datos que NUNCA vio durante entrenamiento."

---

## ğŸ“ CONCEPTOS CLAVE DEL MARTES

**Memoriza:**

- MAE = error promedio (unidades originales)
- RMSE = error promedio penalizando grandes
- RÂ² = porcentaje de variabilidad explicada (0 a 1)
- Menor MAE/RMSE = mejor
- Mayor RÂ² = mejor (cerca de 1)
- Overfitting = memoriza, no generaliza
- Train/Test split es esencial

---

## âœ… CHECKLIST MARTES

- [ ] Entiendo quÃ© es regresiÃ³n en profundidad
- [ ] SÃ© quÃ© miden MAE, RMSE y RÂ²
- [ ] Puedo interpretar valores de mÃ©tricas
- [ ] Entiendo overfitting vs underfitting
- [ ] SÃ© por quÃ© necesitamos train/test split
- [ ] CompletÃ© el ejercicio de interpretar mÃ©tricas
- [ ] CreÃ© 12 flashcards nuevas
- [ ] RepasÃ© flashcards del Lunes (5-10 min)
- [ ] Puedo explicar las mÃ©tricas en voz alta

---

## ğŸ“š RESPUESTAS AL EJERCICIO

**Escenario 1 (temperatura):**

- Â¿Es bueno? **SÃ, excelente**
- Por quÃ©: MAE de 0.8Â°C es muy preciso, RÂ² de 0.94 es excelente. RMSE cercano a MAE = sin outliers.

**Escenario 2 (acciones):**

- Â¿Es bueno? **NO, dÃ©bil**
- Por quÃ©: RÂ² de 0.35 es bajo, explica solo 35% de variabilidad. MAE de $45 en rango $50-500 es alto. RMSE >> MAE indica errores grandes variables.

**Escenario 3 (hospitalizaciÃ³n):**

- Â¿Es bueno? **SÃ, moderado/bueno**
- Por quÃ©: RÂ² de 0.75 es bueno. MAE de 1.5 dÃ­as es razonable.
- RMSE >> MAE indica: Hay algunos pacientes con errores de predicciÃ³n grandes (outliers), quizÃ¡s casos complicados.

**Escenario 4 (comparar modelos):**

- **Elegir: Modelo B**
- Por quÃ©: Aunque tiene MAE ligeramente mayor, tiene RÂ² mejor (0.85 vs 0.82) y RMSE mucho mÃ¡s cercano a MAE (errores mÃ¡s consistentes, menos outliers). Modelo B es mÃ¡s estable.

**Escenario 5 (overfitting):**

- Problema: **OVERFITTING**
- Train RÂ² = 0.98 pero Test RÂ² = 0.52 â†’ Memoriza datos de entrenamiento
- Soluciones: MÃ¡s datos, modelo mÃ¡s simple, regularizaciÃ³n, menos features

---

## ğŸŠ Â¡EXCELENTE TRABAJO EN EL MARTES!

**Lo que has logrado hoy:**

âœ… **Dominas quÃ© es regresiÃ³n en profundidad**

- CÃ³mo funciona la regresiÃ³n lineal
- Objetivo: minimizar el error

âœ… **Entiendes las 3 mÃ©tricas clave**

- MAE: error promedio simple
- RMSE: error promedio penalizando grandes
- RÂ²: variabilidad explicada

âœ… **Sabes interpretar mÃ©tricas**

- QuÃ© valores son buenos/malos
- CÃ³mo comparar modelos
- QuÃ© significan los nÃºmeros

âœ… **Conceptos avanzados**

- Overfitting y underfitting
- Train/test split
- Por quÃ© necesitamos evaluaciÃ³n separada

---

## ğŸ“… MAÃ‘ANA (MiÃ©rcoles):

**Tema:** ClasificaciÃ³n y sus mÃ©tricas

- Accuracy, Precision, Recall, F1-Score
- Matriz de confusiÃ³n
- CuÃ¡ndo usar cada mÃ©trica
- Diferencias con regresiÃ³n

**PrepÃ¡rate para:** Conceptos similares pero para categorÃ­as en vez de nÃºmeros

---

## ğŸ’¡ DIFERENCIA CLAVE: RegresiÃ³n vs ClasificaciÃ³n (preview)

**RegresiÃ³n (HOY):**

- Predice: NÃºmeros
- MÃ©tricas: MAE, RMSE, RÂ²
- Pregunta: "Â¿CuÃ¡nto?"

**ClasificaciÃ³n (MAÃ‘ANA):**

- Predice: CategorÃ­as
- MÃ©tricas: Accuracy, Precision, Recall
- Pregunta: "Â¿CuÃ¡l?"

---

## ğŸ¯ MINI QUIZ FINAL (5 min)

**Responde mentalmente (sin mirar):**

1. Â¿QuÃ© mÃ©trica te dice "en promedio me equivoco por X euros"?
2. Â¿QuÃ© mÃ©trica estÃ¡ entre 0 y 1 y sin unidades?
3. Si RÂ² = 0.9, Â¿es un modelo bueno o malo?
4. Si Train RÂ² = 0.99 y Test RÂ² = 0.45, Â¿quÃ© problema hay?
5. Â¿Para quÃ© sirve el test set?

**Respuestas:**

1. MAE
2. RÂ²
3. Bueno/Excelente (explica 90%)
4. Overfitting
5. Para evaluar cÃ³mo generaliza el modelo a datos nuevos

**Si acertaste 4-5:** Â¡Perfecto! Listo para maÃ±ana
**Si acertaste 2-3:** Repasa 10 min mÃ¡s
**Si acertaste 0-1:** Repasa la secciÃ³n de mÃ©tricas completa

---

## ğŸ“Š TABLA RESUMEN PARA IMPRIMIR

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         MÃ‰TRICAS DE REGRESIÃ“N - CHEAT SHEET            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ MAE (Mean Absolute Error)                               â•‘
â•‘ â€¢ QuÃ© mide: Error promedio                              â•‘
â•‘ â€¢ Rango: 0 a âˆ                                          â•‘
â•‘ â€¢ Mejor: 0 (sin error)                                  â•‘
â•‘ â€¢ Unidades: Mismas que objetivo                         â•‘
â•‘ â€¢ InterpretaciÃ³n: "Me equivoco en promedio por X"      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ RMSE (Root Mean Square Error)                           â•‘
â•‘ â€¢ QuÃ© mide: Error promedio (penaliza grandes)          â•‘
â•‘ â€¢ Rango: 0 a âˆ                                          â•‘
â•‘ â€¢ Mejor: 0 (sin error)                                  â•‘
â•‘ â€¢ Unidades: Mismas que objetivo                         â•‘
â•‘ â€¢ Siempre â‰¥ MAE                                         â•‘
â•‘ â€¢ Si RMSE >> MAE â†’ hay outliers                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ RÂ² (R-squared / Coeficiente de DeterminaciÃ³n)          â•‘
â•‘ â€¢ QuÃ© mide: % de variabilidad explicada                â•‘
â•‘ â€¢ Rango: -âˆ a 1                                         â•‘
â•‘ â€¢ Mejor: 1 (perfecto)                                   â•‘
â•‘ â€¢ Sin unidades                                          â•‘
â•‘ â€¢ RÂ² = 0.85 â†’ explica 85% de datos                     â•‘
â•‘ â€¢ RÂ² < 0 â†’ modelo muy malo                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ VALORES DE REFERENCIA                                   â•‘
â•‘ RÂ² > 0.9    â†’ â­â­â­â­â­ Excelente                       â•‘
â•‘ RÂ² 0.7-0.9  â†’ â­â­â­â­ Bueno                             â•‘
â•‘ RÂ² 0.5-0.7  â†’ â­â­â­ Moderado                            â•‘
â•‘ RÂ² < 0.5    â†’ â­â­ DÃ©bil                                 â•‘
â•‘ RÂ² < 0      â†’ ğŸ’€ Horrible                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ PROBLEMAS COMUNES                                       â•‘
â•‘ Overfitting:  Train RÂ² alto, Test RÂ² bajo              â•‘
â•‘ Underfitting: Train RÂ² bajo, Test RÂ² bajo              â•‘
â•‘ Ideal:        Train RÂ² â‰ˆ Test RÂ² (ambos altos)         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ TRAIN/TEST SPLIT                                        â•‘
â•‘ â€¢ Train 80% â†’ Entrenar modelo                           â•‘
â•‘ â€¢ Test 20%  â†’ Evaluar modelo                            â•‘
â•‘ â€¢ NUNCA evaluar con datos de entrenamiento             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ”— CONEXIÃ“N CON AZURE MACHINE LEARNING

**En Azure ML, verÃ¡s estas mÃ©tricas:**

Cuando entrenas un modelo de regresiÃ³n en Azure:

- AutoML muestra automÃ¡ticamente: MAE, RMSE, RÂ²
- Puedes comparar modelos por estas mÃ©tricas
- Azure ML Designer tambiÃ©n muestra estas mÃ©tricas
- En la Semana 2 SÃ¡bado harÃ¡s un lab y verÃ¡s esto en prÃ¡ctica

**Preview del lab del sÃ¡bado:**

```
Azure ML Output:
â”œâ”€â”€ Primary Metric: RÂ² = 0.87
â”œâ”€â”€ Mean Absolute Error: 2,450
â”œâ”€â”€ Root Mean Squared Error: 3,120
â””â”€â”€ Explained Variance: 0.88

"Tu modelo explica 87% de la variabilidad
 con un error promedio de 2,450 unidades"
```

---

## ğŸ¯ EJERCICIO BONUS (Opcional - 10 min)

**Si tienes tiempo extra, piensa en estos escenarios:**

**Escenario A:**
Trabajas para una empresa de seguros que predice costos mÃ©dicos anuales de clientes (rango: $1,000 - $50,000).

Modelo actual:

- MAE = $3,500
- RMSE = $5,200
- RÂ² = 0.72

**Preguntas:**

1. Â¿Es aceptable un error promedio de $3,500?
2. Â¿QuÃ© te dice que RMSE sea mucho mayor que MAE?
3. Â¿CÃ³mo podrÃ­as mejorar el modelo?

---

**Escenario B:**
Predices tiempo de entrega de paquetes (rango: 1-10 dÃ­as).

Modelo A: MAE = 0.5 dÃ­as, RÂ² = 0.65
Modelo B: MAE = 0.8 dÃ­as, RÂ² = 0.80

**Preguntas:**

1. Â¿QuÃ© modelo tiene predicciones mÃ¡s precisas?
2. Â¿QuÃ© modelo explica mejor la variabilidad?
3. Â¿CuÃ¡l elegirÃ­as y por quÃ©?

**Piensa en las respuestas. No hay una respuesta Ãºnica, depende del contexto del negocio.**

---

## ğŸ“– RECURSOS ADICIONALES (Opcional)

**Si quieres profundizar mÃ¡s:**

**Videos recomendados (YouTube):**

- "What is R-squared?" - StatQuest (inglÃ©s con subtÃ­tulos)
- "MAE vs RMSE" - explicaciones visuales
- "Regression metrics explained" - tutoriales cortos

**Microsoft Learn:**

- "Train and evaluate regression models"
- "Interpret machine learning models"

**DocumentaciÃ³n Azure ML:**

- CÃ³mo Azure ML calcula mÃ©tricas
- InterpretaciÃ³n de resultados en Azure ML Studio

---

## ğŸ’­ REFLEXIÃ“N FINAL DEL DÃA

**Antes de terminar, reflexiona 2 minutos:**

1. Â¿QuÃ© mÃ©trica te pareciÃ³ mÃ¡s fÃ¡cil de entender? Â¿Por quÃ©?
2. Â¿QuÃ© concepto te costÃ³ mÃ¡s? (para repasarlo maÃ±ana)
3. Â¿Puedes pensar en un problema de tu trabajo/vida donde usarÃ­as regresiÃ³n?

**Ejemplo de reflexiÃ³n:**
"EntendÃ­ bien MAE porque es muy directo. RÂ² me costÃ³ un poco pero ahora veo que es como un porcentaje de quÃ© tan bien funciona el modelo. En mi trabajo podrÃ­amos usar regresiÃ³n para predecir ventas mensuales..."

---

## ğŸŒ™ ANTES DE DORMIR (5 min)

**Repaso relÃ¡mpago:**

- Cierra los ojos
- Visualiza las 3 mÃ©tricas: MAE, RMSE, RÂ²
- Recuerda: MAE simple, RMSE penaliza grandes, RÂ² es porcentaje
- Piensa en el ejemplo de precios de casas

**Repasa tus flashcards nuevas 1 vez**

**Duerme bien.** Tu cerebro consolidarÃ¡ todo esto mientras duermes. ğŸ˜´

---

## ğŸ“Š PROGRESO SEMANA 2

```
Lunes:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% âœ…
Martes:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% âœ…
MiÃ©rcoles: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   0%
Jueves:    â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   0%
Viernes:   â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   0%
SÃ¡bado:    â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   0%
```

**Horas Semana 2:** 3/10 horas completadas (30%) âœ…
**Progreso Total:** 13/60 horas (21.7%) ğŸ“ˆ

---

**Â¡Nos vemos maÃ±ana MiÃ©rcoles para ClasificaciÃ³n y sus mÃ©tricas!** ğŸš€

**MaÃ±ana aprenderÃ¡s:**

- Accuracy, Precision, Recall, F1-Score
- Matriz de confusiÃ³n (confusion matrix)
- Verdaderos positivos, falsos negativos...
- CuÃ¡ndo usar cada mÃ©trica de clasificaciÃ³n

**SerÃ¡ similar a hoy, pero para categorÃ­as en vez de nÃºmeros.** ğŸ’ª
