# ğŸ”¬ SÃBADO 15 NOV - SEMANA 2: LAB PRÃCTICO - AutoML

**Fecha:** SÃ¡bado 15 de noviembre 2025  
**Semana:** 2 de 6  
**Tema:** Laboratorio prÃ¡ctico - Crear tu primer modelo con AutoML  
**DuraciÃ³n:** 2-3 horas (hands-on)

---

## ğŸ¯ Objetivos del laboratorio

Al finalizar hoy habrÃ¡s:

- âœ… Creado un experimento AutoML completo en Azure ML Studio
- âœ… Configurado datos, compute y parÃ¡metros del experimento
- âœ… Entrenado un modelo de clasificaciÃ³n o regresiÃ³n
- âœ… Analizado resultados y mÃ©tricas
- âœ… Comparado diferentes modelos
- âœ… Entendido cÃ³mo interpretar las salidas de AutoML
- âœ… Visto en prÃ¡ctica TODO lo aprendido esta semana

---

## ğŸ“‹ ANTES DE EMPEZAR

### âœ… Pre-requisitos

**Necesitas tener:**

- [ ] Cuenta de Azure activa (gratuita o de pago)
- [ ] Azure ML Workspace creado (lo hiciste el jueves)
- [ ] Navegador web actualizado
- [ ] ConexiÃ³n a internet estable

**Si NO tienes workspace:**

- Sigue las instrucciones del Jueves para crearlo
- Toma 5-10 minutos

---

### ğŸ§  Conceptos que aplicarÃ¡s hoy

**De toda la semana:**

- Lunes: Tipos de ML (supervisado/no supervisado)
- Martes: MÃ©tricas de regresiÃ³n (RMSE, RÂ², MAE)
- MiÃ©rcoles: MÃ©tricas de clasificaciÃ³n (Accuracy, Precision, Recall, AUC)
- Jueves: Azure ML Workspace, compute, datasets
- Viernes: AutoML (ensemble, featurization, early stopping)

**Â¡Hoy pondrÃ¡s TODO en prÃ¡ctica!** ğŸ’ª

---

## ğŸ”¬ LABORATORIO: OpciÃ³n A - ClasificaciÃ³n (Diabetes)

### Escenario del proyecto

**Problema de negocio:**
Predecir si un paciente tiene diabetes basÃ¡ndose en datos mÃ©dicos.

**Tipo de ML:** ClasificaciÃ³n binaria (SÃ­ diabetes / No diabetes)

**Dataset:** Pima Indians Diabetes Dataset

- 768 pacientes
- 8 caracterÃ­sticas mÃ©dicas
- Variable objetivo: diabetes (0=No, 1=SÃ­)

---

## ğŸ“ PASO 1: Preparar el dataset (15 minutos)

### 1.1 Descargar el dataset

**OpciÃ³n A: Desde Azure ML Studio**

```
1. Ve a Azure ML Studio (ml.azure.com)
2. Selecciona tu workspace
3. En el menÃº izquierdo â†’ Data
4. Busca "diabetes" en sample datasets
```

**OpciÃ³n B: Subir manualmente**

**URL del dataset:**

```
https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv
```

**Columnas:**

1. Pregnancies (embarazos)
2. Glucose (glucosa)
3. BloodPressure (presiÃ³n arterial)
4. SkinThickness (grosor piel)
5. Insulin (insulina)
6. BMI (Ã­ndice masa corporal)
7. DiabetesPedigreeFunction (funciÃ³n pedigrÃ­)
8. Age (edad)
9. Outcome (resultado: 0=No diabetes, 1=SÃ­ diabetes)

---

### 1.2 Crear dataset en Azure ML

```
Pasos en Azure ML Studio:

1. MenÃº izquierdo â†’ Data â†’ Create

2. ConfiguraciÃ³n bÃ¡sica:
   Name: diabetes-dataset
   Type: Tabular
   Description: Pima Indians Diabetes data

3. Data source:
   - From web files
   - Web URL: [pega la URL de arriba]

4. Settings:
   - File format: Delimited
   - Delimiter: Comma
   - Encoding: UTF-8
   - Column headers: No headers (usaremos nombres por defecto)
   - Skip rows: 0

5. Schema:
   Renombrar columnas:
   - Column1 â†’ Pregnancies
   - Column2 â†’ Glucose
   - Column3 â†’ BloodPressure
   - Column4 â†’ SkinThickness
   - Column5 â†’ Insulin
   - Column6 â†’ BMI
   - Column7 â†’ DiabetesPedigreeFunction
   - Column8 â†’ Age
   - Column9 â†’ Outcome

6. Review â†’ Create
```

**â±ï¸ Tiempo:** ~5 minutos

---

### 1.3 Explorar el dataset

```
1. En Data, click en tu dataset "diabetes-dataset"

2. Tab "Explore":
   - Observa las primeras filas
   - Revisa distribuciÃ³n de Outcome (0 y 1)
   - Nota valores estadÃ­sticos

3. Tab "Profile":
   - Genera profile si no existe
   - Observa:
     * Missing values (valores faltantes)
     * Distribuciones
     * Outliers potenciales

ğŸ“Š Observaciones esperadas:
- ~500 pacientes sin diabetes (Outcome=0)
- ~268 pacientes con diabetes (Outcome=1)
- Clases ligeramente desbalanceadas
```

---

## ğŸ¤– PASO 2: Configurar experimento AutoML (20 minutos)

### 2.1 Crear nuevo experimento AutoML

```
1. MenÃº izquierdo â†’ Automated ML

2. Click "+ New Automated ML job"

3. Select dataset:
   - Elige "diabetes-dataset"
   - Next

4. Configure job:
   Experiment name: diabetes-classification-exp
   New experiment name: diabetes-prediction
   Target column: Outcome
   Compute target: [selecciona o crea compute cluster]
```

---

### 2.2 Configurar compute (si no tienes)

**Si NO tienes compute cluster:**

```
Create new compute:

1. Click "+ New"

2. ConfiguraciÃ³n:
   Compute name: cpu-cluster-automl
   VM type: CPU
   VM priority: Dedicated
   VM size: Standard_DS3_v2 (4 cores, 14GB RAM)

3. Scaling:
   Min nodes: 0 (ahorro de costos)
   Max nodes: 4 (paralelizaciÃ³n)
   Idle seconds: 120 (escala a 0 despuÃ©s de 2 min inactivo)

4. Create â†’ espera 3-5 minutos

ğŸ’¡ Esto escala a 0 cuando no se usa = NO PAGAS cuando inactivo
```

**Si YA tienes compute:**

- SelecciÃ³nalo de la lista

---

### 2.3 Configurar task y settings

```
5. Task type: Classification â† IMPORTANTE

6. Additional configuration settings:

   Primary metric: AUC_weighted
   (porque clases estÃ¡n ligeramente desbalanceadas)

   Explain best model: âœ“ (ver feature importance)

   Blocked algorithms: (ninguno por ahora)

   Exit criterion:
   - Training job time (hours): 0.5 (30 minutos)
   - Metric score threshold: 0.90 (para si AUC â‰¥ 0.90)

   Concurrency:
   - Max concurrent iterations: 4
   (igual al max nodes del cluster)

7. Validation and test:

   Validation type: k-fold cross-validation
   Number of cross validations: 5

   Test dataset: None (usaremos validation)

8. Next
```

---

### 2.4 Revisar y enviar

```
9. Review:
   - Verifica toda la configuraciÃ³n
   - Task: Classification âœ“
   - Primary metric: AUC_weighted âœ“
   - Target: Outcome âœ“
   - Timeout: 0.5 hours âœ“

10. Submit training job

11. VerÃ¡s:
    "Submitting AutoML job..."
    "Job submitted successfully"

12. Click "View job" o ve a:
    Automated ML â†’ diabetes-classification-exp
```

**â±ï¸ El entrenamiento tomarÃ¡ 15-30 minutos**

---

## â³ MIENTRAS ESPERA EL ENTRENAMIENTO (15-30 min)

### Actividades durante la espera:

**1. Observa el progreso en tiempo real:**

```
En la pÃ¡gina del experimento verÃ¡s:
- Status: Running
- Child runs: Modelos probados hasta ahora
- Best model so far: Mejor modelo actual
- Best metric: AUC actual del mejor modelo
```

**2. Explora los modelos que va probando:**

```
Tab "Models":
- Ve la lista de algoritmos probados
- Observa mÃ©tricas de cada uno
- Nota cuÃ¡les son ensemble
```

**Algoritmos tÃ­picos que probarÃ¡:**

- LogisticRegression
- RandomForest
- LightGBM
- XGBoostClassifier
- VotingEnsemble â† Probablemente el ganador
- StackEnsemble

**3. Repasa conceptos de la semana:**

- Â¿QuÃ© es un ensemble model?
- Â¿Por quÃ© AUC_weighted es buena mÃ©trica aquÃ­?
- Â¿QuÃ© esperas ver en la confusion matrix?

**4. Prepara preguntas:**

- Â¿QuÃ© modelo esperas que gane?
- Â¿SerÃ¡ importante Precision o Recall?
- Â¿CÃ³mo interpretarÃ¡s los resultados?

---

## ğŸ“Š PASO 3: Analizar resultados (30 minutos)

### 3.1 Ver el mejor modelo

**Cuando termine el experimento:**

```
1. Status cambia a: "Completed"

2. Tab "Overview":
   - Best model algorithm: [ej: VotingEnsemble]
   - Best model AUC_weighted: [ej: 0.8542]

3. Click en "View best model"
```

---

### 3.2 Explorar mÃ©tricas del modelo

```
En la pÃ¡gina del Best Model:

Tab "Metrics":

ğŸ“Š Classification Metrics:
- Accuracy: Â¿QuÃ© % de predicciones correctas?
- AUC weighted: Â¿Capacidad de discriminaciÃ³n?
- Precision: Â¿Confiable cuando dice "diabetes"?
- Recall: Â¿Detecta todos los casos de diabetes?
- F1 score: Â¿Balance entre Precision y Recall?

ğŸ” Ejemplo de resultados esperados:
- Accuracy: ~0.77 (77%)
- AUC: ~0.85 (85%)
- Precision: ~0.72 (72%)
- Recall: ~0.65 (65%)
- F1: ~0.68 (68%)
```

---

### 3.3 Analizar Confusion Matrix

```
Tab "Metrics" â†’ Scroll down â†’ Confusion Matrix

Ejemplo de matriz esperada:

                  Predicted
              No diabetes  Diabetes
Actual  No        420        80
        Diabetes   95       173

ğŸ“Š InterpretaciÃ³n:

True Negatives (TN): 420
- Correctamente identificados SIN diabetes

True Positives (TP): 173
- Correctamente identificados CON diabetes

False Positives (FP): 80
- Error: dijo diabetes pero NO la tienen

False Negatives (FN): 95
- PELIGROSO: dijo NO diabetes pero SÃ la tienen
```

---

### 3.4 Calcular mÃ©tricas manualmente

**ğŸ§® Ejercicio prÃ¡ctico:**

Usando la confusion matrix del ejemplo:

```
TN = 420, FP = 80
FN = 95,  TP = 173
Total = 768

1. Accuracy:
   (420 + 173) / 768 = 593 / 768 = 0.772 = 77.2%

2. Precision:
   173 / (173 + 80) = 173 / 253 = 0.684 = 68.4%

3. Recall:
   173 / (173 + 95) = 173 / 268 = 0.646 = 64.6%

4. F1:
   2 Ã— (0.684 Ã— 0.646) / (0.684 + 0.646) = 0.664 = 66.4%
```

**ğŸ’¡ Verifica que coincidan con las mÃ©tricas mostradas en Azure ML**

---

### 3.5 Analizar ROC Curve

```
Tab "Metrics" â†’ Scroll down â†’ ROC Curve

ğŸ“ˆ Observa:

1. La curva debe estar por encima de la lÃ­nea diagonal
2. AUC (Ã¡rea sombreada) deberÃ­a ser ~0.85
3. Cuanto mÃ¡s arriba-izquierda, mejor

InterpretaciÃ³n AUC = 0.85:
"El modelo tiene 85% de probabilidad de darle mayor
score a un paciente con diabetes que a uno sin diabetes"

â†’ Es un modelo BUENO (0.8-0.9 es muy bueno)
```

---

### 3.6 Ver Feature Importance

```
Tab "Explanations" (si activaste "Explain best model")

ğŸ“Š Features mÃ¡s importantes (ejemplo tÃ­pico):

1. Glucose: 0.28 (28%) â† MÃS IMPORTANTE
2. BMI: 0.18 (18%)
3. Age: 0.15 (15%)
4. DiabetesPedigreeFunction: 0.12 (12%)
5. Pregnancies: 0.10 (10%)
6. BloodPressure: 0.08 (8%)
7. Insulin: 0.05 (5%)
8. SkinThickness: 0.04 (4%)

ğŸ’¡ InterpretaciÃ³n:
- Glucose es el predictor mÃ¡s fuerte
- BMI y Age tambiÃ©n muy importantes
- SkinThickness tiene poco poder predictivo
```

---

### 3.7 Comparar mÃºltiples modelos

```
Vuelve al experimento â†’ Tab "Models"

ğŸ“Š Compara top 3 modelos:

Modelo                  AUC    Accuracy  Precision  Recall
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VotingEnsemble         0.854    0.772     0.684    0.646
StackEnsemble          0.851    0.769     0.680    0.643
XGBoostClassifier      0.842    0.765     0.672    0.638
LightGBM               0.838    0.761     0.668    0.635
RandomForest           0.825    0.753     0.655    0.625

ğŸ¯ Observaciones:
- Ensembles ganan (VotingEnsemble #1)
- Diferencias pequeÃ±as entre top modelos
- Trade-off entre Precision y Recall visible
```

---

## ğŸ¤” PASO 4: InterpretaciÃ³n de negocio (15 minutos)

### 4.1 Â¿Es un buen modelo?

**Contexto mÃ©dico:**

```
MÃ©tricas:
- Recall: 64.6% (detecta 65% de casos de diabetes)
- Precision: 68.4% (68% confiable cuando dice "diabetes")

âš ï¸ PROBLEMA: Recall bajo

Recall = 64.6% significa:
- De 100 personas CON diabetes
- Solo detectamos 65
- Nos perdemos 35 casos (False Negatives)

En medicina esto es GRAVE:
â†’ 35 personas con diabetes no diagnosticadas
â†’ No reciben tratamiento
â†’ Complicaciones de salud
```

---

### 4.2 Â¿QuÃ© podrÃ­amos hacer?

**Opciones para mejorar:**

**1. Ajustar el umbral de clasificaciÃ³n:**

```
En vez de umbral = 0.5, usar umbral = 0.3

Efecto:
âœ… Aumenta Recall (detectamos mÃ¡s casos)
âŒ Disminuye Precision (mÃ¡s falsos positivos)

Trade-off aceptable en medicina:
Mejor tener algunos falsos positivos (confirmar
con mÃ¡s pruebas) que perder casos reales.
```

**2. Recolectar mÃ¡s datos:**

```
- El dataset tiene solo 268 casos de diabetes
- MÃ¡s datos â†’ mejor modelo
- Especialmente en la clase minoritaria
```

**3. Feature engineering:**

```
- Crear features combinadas (ej: BMI * Age)
- Transformaciones (logaritmos, polinomios)
- Agregar mÃ¡s variables mÃ©dicas
```

**4. Probar otros algoritmos:**

```
- Deep learning (redes neuronales)
- Modelos especializados en clases desbalanceadas
```

**5. Cambiar primary metric:**

```
En vez de AUC_weighted, usar:
- Recall (para maximizar detecciÃ³n)
- F1_score_weighted (balance)
```

---

### 4.3 DecisiÃ³n de negocio

**Pregunta clave:**
"Â¿QuÃ© es mÃ¡s costoso?"

**OpciÃ³n A: Alta Precision (conservador)**

```
âœ… Evitas tratamientos innecesarios
âŒ Te pierdes muchos casos reales
```

**OpciÃ³n B: Alto Recall (agresivo)**

```
âœ… Detectas casi todos los casos
âŒ Muchas personas sin diabetes reciben diagnÃ³stico falso
```

**En diabetes:**

```
â†’ Priorizar RECALL

RazÃ³n:
- Diabetes no diagnosticada â†’ complicaciones graves
- Falso positivo â†’ hacer mÃ¡s pruebas (confirmar)
- Costo de FN >> Costo de FP
```

---

## ğŸ”„ PASO 5 (OPCIONAL): Repetir experimento optimizado (30 min)

### 5.1 Crear experimento mejorado

**Si quieres mejorar el modelo:**

```
1. New Automated ML job

2. Same dataset: diabetes-dataset

3. Experiment name: diabetes-classification-exp-v2

4. Configure job:
   Target: Outcome
   Compute: cpu-cluster-automl

5. Task: Classification

6. CAMBIOS:
   Primary metric: Recall_score_weighted â† CAMBIO
   (en vez de AUC_weighted)

   Training job time: 1.0 hours â† MÃ¡s tiempo

   Metric score threshold: 0.75 (75% recall)

   Enable deep learning: âœ“ â† NUEVO

7. Submit
```

**Espera:** 30-60 minutos

**Resultado esperado:**

- Mayor Recall (~75-80%)
- Menor Precision (~60-65%)
- Mejor balance para caso mÃ©dico

---

## ğŸ“ PASO 6: Documentar aprendizajes (15 minutos)

### 6.1 Completa esta evaluaciÃ³n

**Responde en tu cuaderno:**

```
1. Â¿QuÃ© tipo de ML usaste? (clasificaciÃ³n/regresiÃ³n)

2. Â¿QuÃ© algoritmo ganÃ³?

3. MÃ©tricas del mejor modelo:
   - Accuracy: ____%
   - AUC: ____
   - Precision: ____%
   - Recall: ____%
   - F1: ____%

4. Â¿CuÃ¡l fue la feature mÃ¡s importante?

5. Â¿Es un buen modelo para uso mÃ©dico? Â¿Por quÃ©?

6. Â¿QuÃ© mÃ©trica priorizarÃ­as? Â¿Por quÃ©?

7. Â¿QuÃ© aprendiste de los ensembles?

8. Si tuvieras mÃ¡s tiempo, Â¿quÃ© mejorarÃ­as?
```

---

### 6.2 ReflexiÃ³n final

**Escribe 2-3 pÃ¡rrafos sobre:**

1. **Experiencia prÃ¡ctica:**
   - Â¿Fue fÃ¡cil usar AutoML?
   - Â¿QuÃ© te sorprendiÃ³?
   - Â¿QuÃ© fue mÃ¡s difÃ­cil?

2. **ConexiÃ³n con teorÃ­a:**
   - Â¿Viste en prÃ¡ctica los conceptos de la semana?
   - Â¿Entiendes mejor las mÃ©tricas ahora?
   - Â¿QuÃ© concepto te quedÃ³ mÃ¡s claro?

3. **AplicaciÃ³n futura:**
   - Â¿CÃ³mo usarÃ­as esto en tu trabajo?
   - Â¿QuÃ© otros problemas podrÃ­as resolver?

---

## ğŸ”¬ LABORATORIO ALTERNATIVO: OpciÃ³n B - RegresiÃ³n (OPCIONAL)

**Si prefieres hacer regresiÃ³n en vez de clasificaciÃ³n:**

### Dataset: PredicciÃ³n de precios de casas

```
Dataset: California Housing
URL: Disponible en Azure ML samples

Variables:
- MedInc (ingreso medio)
- HouseAge (edad de la casa)
- AveRooms (habitaciones promedio)
- AveBedrms (dormitorios promedio)
- Population (poblaciÃ³n)
- AveOccup (ocupaciÃ³n promedio)
- Latitude (latitud)
- Longitude (longitud)
Target: MedianHouseValue (precio medio)

Pasos similares pero:
- Task type: Regression
- Primary metric: Normalized root mean squared error
- MÃ©tricas: RMSE, MAE, RÂ²
```

---

## âœ… CHECKLIST DEL LABORATORIO

Al final del dÃ­a, debes haber:

- [ ] Creado dataset en Azure ML
- [ ] Configurado experimento AutoML completo
- [ ] Esperado y monitoreado el entrenamiento
- [ ] Analizado el mejor modelo
- [ ] Interpretado confusion matrix
- [ ] Calculado mÃ©tricas manualmente
- [ ] Visto ROC curve y AUC
- [ ] Analizado feature importance
- [ ] Comparado mÃºltiples modelos
- [ ] Reflexionado sobre aplicaciÃ³n de negocio
- [ ] Documentado aprendizajes
- [ ] (Opcional) Creado experimento optimizado

---

## ğŸ¯ CONCEPTOS QUE PRACTICASTE HOY

### De la semana completa:

**Lunes - Tipos de ML:**

- âœ… Usaste supervised learning (clasificaciÃ³n)
- âœ… Viste datos etiquetados (Outcome conocido)

**Martes - RegresiÃ³n:**

- âœ… Si hiciste OpciÃ³n B, aplicaste RMSE, MAE, RÂ²
- âœ… Entendiste diferencia con clasificaciÃ³n

**MiÃ©rcoles - ClasificaciÃ³n:**

- âœ… Calculaste Accuracy, Precision, Recall, F1
- âœ… Analizaste confusion matrix en detalle
- âœ… Viste ROC curve y AUC en prÃ¡ctica

**Jueves - Azure ML:**

- âœ… Usaste workspace, compute, datasets
- âœ… Navegaste Azure ML Studio
- âœ… Configuraste recursos

**Viernes - AutoML:**

- âœ… Configuraste experimento completo
- âœ… Estableciste primary metric y exit criterion
- âœ… Viste ensemble models ganar
- âœ… Entendiste featurization automÃ¡tica

---

## ğŸ“ PREGUNTAS DE REFLEXIÃ“N

### TÃ©cnicas:

1. Â¿Por quÃ© VotingEnsemble suele ganar?
2. Â¿CÃ³mo afecta el exit criterion al resultado?
3. Â¿Por quÃ© AUC es mejor que Accuracy aquÃ­?
4. Â¿QuÃ© significa que Glucose sea la feature mÃ¡s importante?
5. Â¿CÃ³mo interpretarÃ­as un AUC de 0.95?

### De negocio:

6. Â¿UsarÃ­as este modelo en producciÃ³n? Â¿Por quÃ©?
7. Â¿QuÃ© le dirÃ­as al doctor sobre Recall del 65%?
8. Â¿CÃ³mo balancearÃ­as Precision vs Recall en medicina?
9. Â¿QuÃ© otros datos pedirÃ­as para mejorar el modelo?
10. Â¿CÃ³mo explicarÃ­as feature importance a un no tÃ©cnico?

---

## ğŸ’¡ TROUBLESHOOTING

### Problemas comunes:

**1. "Compute cluster no se crea"**

```
SoluciÃ³n:
- Verifica lÃ­mites de tu suscripciÃ³n
- Intenta otra regiÃ³n
- Usa VM size mÃ¡s pequeÃ±o (DS2_v2)
```

**2. "Experimento falla inmediatamente"**

```
SoluciÃ³n:
- Verifica que target column estÃ© correcta
- Asegura que no haya errores en dataset
- Revisa logs en la pÃ¡gina del experimento
```

**3. "No veo ROC curve"**

```
SoluciÃ³n:
- Solo aparece en clasificaciÃ³n binaria
- Espera a que termine el experimento
- Tab "Metrics" del best model
```

**4. "Feature importance no aparece"**

```
SoluciÃ³n:
- AsegÃºrate de activar "Explain best model"
- Tab "Explanations" del best model
- Puede tardar unos minutos en generarse
```

**5. "Compute no escala a cero"**

```
SoluciÃ³n:
- Espera 2 minutos (idle seconds: 120)
- Verifica en "Compute" â†’ "Compute clusters"
- Manualmente scale down si es necesario
```

---

## ğŸ“Š COMPARACIÃ“N: TUS RESULTADOS vs ESPERADOS

### Completa esta tabla:

| MÃ©trica        | Esperado       | Tus resultados | Â¿Mejor/Peor/Igual? |
| -------------- | -------------- | -------------- | ------------------ |
| Accuracy       | ~77%           | \_\_\_%        | \_\_\_             |
| AUC            | ~0.85          | \_\_\_         | \_\_\_             |
| Precision      | ~68%           | \_\_\_%        | \_\_\_             |
| Recall         | ~65%           | \_\_\_%        | \_\_\_             |
| F1 Score       | ~66%           | \_\_\_%        | \_\_\_             |
| Best Algorithm | VotingEnsemble | \_\_\_         | \_\_\_             |
| Training Time  | 20-30 min      | \_\_\_ min     | \_\_\_             |

**Si tus resultados son diferentes:**

- âœ… Normal, AutoML tiene componente aleatorio
- âœ… Resultados en Â±5% son equivalentes
- âœ… Lo importante es entender las mÃ©tricas

---

## ğŸš€ PRÃ“XIMOS PASOS

### DespuÃ©s del laboratorio:

**1. Limpia recursos (IMPORTANTE):**

```
Para evitar costos:

1. Ve a "Compute" â†’ "Compute clusters"
2. Verifica que cluster estÃ© en 0 nodes
3. Si quieres, DELETE el cluster
4. Los experimentos y modelos se conservan
```

**2. Guarda tu notebook (si hiciste anotaciones):**

```
- Captura de pantalla de mÃ©tricas
- Notas sobre interpretaciÃ³n
- Decisiones que tomaste
```

**3. Practica con otro dataset:**

```
Ideas:
- Titanic (clasificaciÃ³n: sobreviviÃ³/no)
- Boston Housing (regresiÃ³n: precio casas)
- Iris (clasificaciÃ³n multiclase: 3 flores)
```

---

## ğŸ“… RESUMEN DE LA SEMANA 2

```
Semana 2: Machine Learning en profundidad
â”œâ”€â”€ âœ… Lunes 10: Tipos de ML profundo
â”œâ”€â”€ âœ… Martes 11: RegresiÃ³n y mÃ©tricas
â”œâ”€â”€ âœ… MiÃ©rcoles 12: ClasificaciÃ³n y mÃ©tricas
â”œâ”€â”€ âœ… Jueves 13: Azure ML workspace
â”œâ”€â”€ âœ… Viernes 14: AutoML
â”œâ”€â”€ âœ… SÃ¡bado 15: LAB - Crear primer modelo (HOY COMPLETADO)
â””â”€â”€ ğŸ“… Domingo 16: DESCANSO
```

**Â¡Completaste el 86% de la Semana 2!** ğŸ‰

---

## ğŸŠ Â¡FELICITACIONES!

### Lo que lograste hoy:

âœ… **Creaste tu primer modelo de ML** en la nube  
âœ… **Aplicaste AutoML** end-to-end  
âœ… **Analizaste mÃ©tricas** en contexto real  
âœ… **Interpretaste resultados** de negocio  
âœ… **Conectaste teorÃ­a con prÃ¡ctica** de toda la semana

### Habilidades desarrolladas:

- ğŸ”§ Configurar experimentos AutoML
- ğŸ“Š Analizar confusion matrix
- ğŸ“ˆ Interpretar ROC curves
- ğŸ§  Feature importance analysis
- ğŸ’¼ Decisiones basadas en mÃ©tricas
- â˜ï¸ Trabajar con Azure ML Studio

---

## ğŸ“š MATERIAL COMPLEMENTARIO (Opcional)

### Videos recomendados:

1. **"Azure AutoML Tutorial"** - Microsoft Learn (20 min)
2. **"Understanding Model Metrics"** - Explicaciones visuales
3. **"Feature Importance Explained"** - InterpretaciÃ³n prÃ¡ctica

### Lecturas:

1. **Microsoft Learn:** "Train models with AutoML"
2. **DocumentaciÃ³n:** "Classification metrics in Azure ML"
3. **Blog:** "Best practices for AutoML experiments"

---

## ğŸ’­ REFLEXIÃ“N FINAL

**Antes de terminar, piensa:**

1. **Â¿QuÃ© fue lo mÃ¡s sorprendente del lab?**
   - Â¿La facilidad de AutoML?
   - Â¿Los ensembles ganando?
   - Â¿La importancia del trade-off Precision/Recall?

2. **Â¿QuÃ© concepto entiendes mejor ahora?**
   - Â¿MÃ©tricas de clasificaciÃ³n?
   - Â¿Feature importance?
   - Â¿Ensemble models?

3. **Â¿CÃ³mo aplicarÃ­as esto en tu contexto?**
   - Â¿QuÃ© problemas podrÃ­as resolver?
   - Â¿QuÃ© datos tienes disponibles?
   - Â¿QuÃ© mÃ©tricas priorizarÃ­as?

---

## ğŸ“ Â¿NECESITAS AYUDA?

**Si tienes dudas:**

- Repasa el material del dÃ­a correspondiente
- Consulta la documentaciÃ³n de Azure ML
- Pregunta en los foros de Microsoft Learn
- **PregÃºntame a mÃ­** - estoy aquÃ­ para ayudarte

---

## ğŸ¯ PREPARACIÃ“N PARA MAÃ‘ANA

### Domingo 16: DÃ­a de descanso

**NO estudies maÃ±ana** âœ‹

**En su lugar:**

- ğŸ˜´ Descansa bien
- ğŸ§˜ RelÃ¡jate
- ğŸš¶ Haz ejercicio
- ğŸ® DiviÃ©rtete
- ğŸ’­ Deja que tu cerebro consolide lo aprendido

**Tu cerebro necesita tiempo para:**

- Consolidar memorias
- Crear conexiones neuronales
- Prepararse para Semana 3

**Lunes empezamos Semana 3:**

- Computer Vision
- Azure AI Vision services
- Reconocimiento de imÃ¡genes
- OCR y Face API

---

## âœ… CHECKLIST FINAL

Antes de cerrar Azure:

- [ ] Experimento completado exitosamente
- [ ] MÃ©tricas analizadas y documentadas
- [ ] Compute cluster escalado a 0 nodes
- [ ] Reflexiones escritas en tu cuaderno
- [ ] Screenshots guardados (opcional)
- [ ] Entendiste los conceptos principales
- [ ] Listo para descansar maÃ±ana

---

**ğŸ‰ Â¡EXCELENTE TRABAJO EN EL LABORATORIO!** ğŸ‰

**Has dado un paso ENORME en tu preparaciÃ³n para el AI-900.**

**Descansa bien este domingo. Â¡Te lo mereces!** ğŸ’ªğŸ˜Š

---

_Ãšltima actualizaciÃ³n: SÃ¡bado 15 de noviembre 2025_  
_Semana 2 de 6 - DÃ­a 6 de 7 (Lab PrÃ¡ctico)_  
_Â¡Semana 2 casi completa!_
