## 40 Preguntas Estilo Examen Microsoft AI-900 con Casos Reales

---

## ğŸ¯ SOBRE ESTE BANCO DE PREGUNTAS

**PropÃ³sito:** PrÃ¡ctica adicional con escenarios realistas del mundo empresarial

**CaracterÃ­sticas:**
- âœ… 40 preguntas nuevas (adicionales a las 30 del viernes)
- âœ… Escenarios basados en casos reales de empresas
- âœ… Nivel de dificultad variado (fÃ¡cil, medio, difÃ­cil)
- âœ… Explicaciones detalladas
- âœ… Tips para identificar patrones

**Formato:**
- OpciÃ³n mÃºltiple (4 opciones)
- Algunas preguntas multi-select (donde se indica)
- Estilo idÃ©ntico al examen AI-900 real

**Tiempo sugerido:** 60-75 minutos

---

## ğŸ“Š SECCIÃ“N 1: SENTIMENT ANALYSIS & OPINION MINING - CASOS REALES (10 preguntas)

### Pregunta 1 - Retail E-commerce
**DIFICULTAD: ğŸŸ¢ FÃ¡cil**

**ESCENARIO:**
Una tienda online recibe esta reseÃ±a de un producto:
```
"El producto llegÃ³ rÃ¡pido y el empaque era perfecto. Sin embargo, 
la calidad del material es decepcionante para el precio. El color 
tambiÃ©n es diferente al de las fotos."
```

El sistema de Sentiment Analysis devuelve: `sentiment: "mixed"`

**PREGUNTA:**
Â¿Por quÃ© el resultado es "mixed" en lugar de "negative"?

A) Hay un error en el anÃ¡lisis, deberÃ­a ser "negative"  
B) El texto contiene tanto elementos positivos (entrega, empaque) como negativos (calidad, color)  
C) El sistema no tiene suficiente confianza para determinar el sentimiento  
D) "Mixed" significa que el texto es neutral  

<details>
<summary>ğŸ‘‰ Ver respuesta y explicaciÃ³n</summary>

**RESPUESTA CORRECTA: B) El texto contiene tanto elementos positivos (entrega, empaque) como negativos (calidad, color)**

**EXPLICACIÃ“N DETALLADA:**

```
ANÃLISIS DEL TEXTO:

ELEMENTOS POSITIVOS:
âœ… "llegÃ³ rÃ¡pido" 
âœ… "empaque perfecto"

ELEMENTOS NEGATIVOS:
âŒ "calidad decepcionante"
âŒ "color diferente"

RESULTADO:
Como hay balance entre positivo y negativo â†’ MIXED
```

**Por quÃ© las otras son incorrectas:**
- **A)** FALSO: No es error, mixed es vÃ¡lido cuando hay balance
- **C)** FALSO: Mixed no significa baja confianza, significa balance de sentimientos
- **D)** FALSO: Mixed â‰  Neutral. Neutral es ausencia de sentimiento; Mixed es presencia de ambos

**PATRÃ“N PARA EL EXAMEN:**
Cuando veas reseÃ±as con "pero", "sin embargo", "aunque" â†’ piensa en MIXED sentiment

**TIP:**
```
PALABRAS CLAVE que indican MIXED:
- "pero"
- "sin embargo"  
- "aunque"
- Mitad positivo + mitad negativo
```

</details>

---

### Pregunta 2 - AnÃ¡lisis de Redes Sociales
**DIFICULTAD: ğŸŸ¡ Media**

**ESCENARIO:**
Una agencia de marketing analiza 50,000 tweets sobre una nueva pelÃ­cula. Reciben estos confidence scores promedio:

```
Tweet tipo A:
{
  "positive": 0.89,
  "neutral": 0.08,
  "negative": 0.03
}

Tweet tipo B:
{
  "positive": 0.52,
  "neutral": 0.28,
  "negative": 0.20
}
```

**PREGUNTA:**
Â¿QuÃ© recomendaciÃ³n correcta puede hacer la agencia al cliente basÃ¡ndose en estos datos?

A) Ambos tipos de tweets muestran la misma recepciÃ³n positiva  
B) Tweet tipo A muestra recepciÃ³n muy positiva (alta confianza); tipo B muestra recepciÃ³n ligeramente positiva pero mÃ¡s ambigua  
C) Los datos son invÃ¡lidos porque los confidence scores del tipo B no suman 1.00  
D) Tweet tipo B muestra sentimiento negativo predominante  

<details>
<summary>ğŸ‘‰ Ver respuesta y explicaciÃ³n</summary>

**RESPUESTA CORRECTA: B) Tweet tipo A muestra recepciÃ³n muy positiva (alta confianza); tipo B muestra recepciÃ³n ligeramente positiva pero mÃ¡s ambigua**

**EXPLICACIÃ“N DETALLADA:**

```
TWEET TIPO A:
positive: 0.89 â†’ MUY ALTO (89%)
negative: 0.03 â†’ INSIGNIFICANTE (3%)
INTERPRETACIÃ“N: âœ… RecepciÃ³n MUY positiva

TWEET TIPO B:
positive: 0.52 â†’ MEDIO (52%)
neutral: 0.28 â†’ CONSIDERABLE (28%)
negative: 0.20 â†’ NO DESPRECIABLE (20%)
INTERPRETACIÃ“N: âš ï¸ Ligeramente positivo pero AMBIGUO
```

**RECOMENDACIÃ“N AL CLIENTE:**
```
âœ… FORTALEZA: 
Tweets claramente positivos (tipo A) dominan

âš ï¸ ÃREA DE ATENCIÃ“N:
Hay un segmento con opiniones mixtas/ambiguas (tipo B)
â†’ Investigar quÃ© aspectos causan esta ambigÃ¼edad
```

**Por quÃ© las otras son incorrectas:**
- **A)** FALSO: 0.89 (muy claro) â‰  0.52 (ambiguo)
- **C)** FALSO: 0.52 + 0.28 + 0.20 = 1.00 âœ… (suma correctamente)
- **D)** FALSO: Positive (0.52) > Negative (0.20), es positivo aunque dÃ©bil

**CONCEPTO CLAVE:**
```
INTERPRETACIÃ“N DE CONFIDENCE SCORES:

ALTA CONFIANZA (>0.80):
â†’ Sentimiento muy claro
â†’ Confiable para decisiones

MEDIA CONFIANZA (0.50-0.80):
â†’ Sentimiento existe pero con ambigÃ¼edad
â†’ Revisar casos individuales

BAJA CONFIANZA (<0.50):
â†’ Texto muy ambiguo
â†’ RevisiÃ³n manual recomendada
```

**TIP PARA EL EXAMEN:**
No todos los confidence scores altos son iguales. 0.89 y 0.52 ambos indican "positive", pero con niveles muy diferentes de certeza.

</details>

---

### Pregunta 3 - Feedback de Empleados (Opinion Mining)
**DIFICULTAD: ğŸŸ¡ Media**

**ESCENARIO:**
Una empresa de 2,000 empleados realiza encuesta anual de satisfacciÃ³n. Quieren un dashboard que muestre:

```
RESULTADOS DESEADOS:
- Salario: 45% satisfecho, 55% insatisfecho
- Balance vida-trabajo: 78% satisfecho, 22% insatisfecho
- GestiÃ³n: 62% satisfecho, 38% insatisfecho
- Beneficios: 85% satisfecho, 15% insatisfecho
- Cultura: 71% satisfecho, 29% insatisfecho
```

**PREGUNTA:**
Â¿QuÃ© combinaciÃ³n de servicios de Azure AI Language necesitan?

A) Solo Sentiment Analysis (documento completo)  
B) Sentiment Analysis + Key Phrase Extraction  
C) Opinion Mining para identificar targets (aspectos) y sentimiento sobre cada uno  
D) Named Entity Recognition + Sentiment Analysis  

<details>
<summary>ğŸ‘‰ Ver respuesta y explicaciÃ³n</summary>

**RESPUESTA CORRECTA: C) Opinion Mining para identificar targets (aspectos) y sentimiento sobre cada uno**

**EXPLICACIÃ“N DETALLADA:**

```
ANÃLISIS DEL REQUERIMIENTO:

NECESITAN:
âœ… Identificar ASPECTOS especÃ­ficos (salario, balance, gestiÃ³n, etc.)
âœ… Sentimiento SOBRE CADA aspecto
âœ… Porcentajes por aspecto

ESTO ES EXACTAMENTE Opinion Mining:
Target: "salario" â†’ Sentiment: 45% positivo, 55% negativo
Target: "balance vida-trabajo" â†’ Sentiment: 78% positivo, 22% negativo
```

**EJEMPLO DE COMENTARIO:**
```
"Me encanta la cultura de la empresa y los beneficios son excelentes. 
Sin embargo, el salario es bajo comparado con el mercado y la carga 
de trabajo es muy pesada."

SENTIMENT ANALYSIS (bÃ¡sico):
â†’ MIXED (alguna cosa positiva, alguna negativa)
âŒ NO identifica QUÃ‰ aspectos son positivos/negativos

OPINION MINING:
â†’ Target: "cultura" â†’ POSITIVE
â†’ Target: "beneficios" â†’ POSITIVE  
â†’ Target: "salario" â†’ NEGATIVE
â†’ Target: "carga de trabajo" â†’ NEGATIVE
âœ… Identifica sentimiento POR ASPECTO
```

**Por quÃ© las otras son incorrectas:**
- **A)** Solo darÃ­a tono general, no desglose por aspecto
- **B)** Key Phrases identificarÃ­a temas, pero NO asociarÃ­a sentimiento a cada uno
- **D)** NER extrae nombres/fechas, no aspectos con sentimiento

**PATRÃ“N PARA EL EXAMEN:**
```
PALABRAS CLAVE que indican Opinion Mining:
- "aspectos especÃ­ficos"
- "quÃ© caracterÃ­sticas"
- "desglose por categorÃ­a"
- "dashboard por atributo"
- "anÃ¡lisis granular"
```

**TIP:**
Si la pregunta pide identificar MÃšLTIPLES aspectos Y el sentimiento sobre CADA UNO â†’ Opinion Mining

</details>

---

### Pregunta 4 - AnÃ¡lisis Multinivel
**DIFICULTAD: ğŸ”´ DifÃ­cil**

**ESCENARIO:**
Un sistema analiza reseÃ±as de hoteles. Para esta reseÃ±a especÃ­fica:

```
"El hotel es hermoso y estÃ¡ en el centro de la ciudad. 
Las habitaciones son espaciosas y limpias. 
El personal fue extremadamente grosero y poco profesional. 
El desayuno era terrible, comida frÃ­a y sin sabor. 
La piscina del hotel es espectacular."
```

Azure AI Language devuelve:
```json
{
  "document": {
    "sentiment": "mixed",
    "confidenceScores": {
      "positive": 0.48,
      "neutral": 0.07,
      "negative": 0.45
    }
  },
  "sentences": [
    {"text": "El hotel es hermoso...", "sentiment": "positive"},
    {"text": "Las habitaciones son...", "sentiment": "positive"},
    {"text": "El personal fue...", "sentiment": "negative"},
    {"text": "El desayuno era...", "sentiment": "negative"},
    {"text": "La piscina del hotel...", "sentiment": "positive"}
  ]
}
```

**PREGUNTA:**
Un gerente del hotel pregunta: "Â¿Por quÃ© el anÃ¡lisis dice 'mixed' si tenemos 3 oraciones positivas y solo 2 negativas?" Â¿CuÃ¡l es la explicaciÃ³n CORRECTA?

A) Hay un error en el sistema, deberÃ­a marcar como "positive" por mayorÃ­a  
B) El anÃ¡lisis a nivel de documento considera el peso emocional de las palabras, no solo el conteo de oraciones  
C) El sistema estÃ¡ mal entrenado para espaÃ±ol  
D) Mixed siempre se asigna cuando hay cualquier oraciÃ³n negativa, sin importar la proporciÃ³n  

<details>
<summary>ğŸ‘‰ Ver respuesta y explicaciÃ³n</summary>

**RESPUESTA CORRECTA: B) El anÃ¡lisis a nivel de documento considera el peso emocional de las palabras, no solo el conteo de oraciones**

**EXPLICACIÃ“N DETALLADA:**

```
ANÃLISIS PROFUNDO:

ORACIONES POSITIVAS (3):
1. "hermoso", "centro de la ciudad" â†’ Moderadamente positivo
2. "espaciosas", "limpias" â†’ Moderadamente positivo
3. "espectacular" â†’ Muy positivo

ORACIONES NEGATIVAS (2):
4. "EXTREMADAMENTE grosero", "poco profesional" â†’ MUY negativo
5. "TERRIBLE", "frÃ­a", "sin sabor" â†’ MUY negativo

PALABRAS CLAVE:
âœ… Positivas: hermoso, espaciosas, limpias, espectacular
âŒ Negativas: EXTREMADAMENTE, grosero, poco profesional, TERRIBLE

INTENSIDAD:
Las palabras negativas tienen MAYOR intensidad emocional
â†’ "EXTREMADAMENTE grosero" pesa mÃ¡s que "hermoso"
â†’ "TERRIBLE" pesa mÃ¡s que "espaciosas"
```

**CONCEPTO IMPORTANTE:**
El modelo de Sentiment Analysis no cuenta oraciones, sino que:
1. Analiza intensidad de palabras emocionales
2. Considera contexto y modificadores (extremadamente, muy, poco)
3. Pondera el impacto emocional general

```
CONTEO SIMPLE (incorrecto):
3 positivas vs 2 negativas = POSITIVE âŒ

ANÃLISIS REAL (correcto):
Peso emocional total â‰ˆ equilibrado = MIXED âœ…
```

**Por quÃ© las otras son incorrectas:**
- **A)** El sistema NO funciona por conteo de oraciones, sino por peso emocional
- **C)** El anÃ¡lisis es correcto; el espaÃ±ol estÃ¡ bien soportado
- **D)** FALSO: Mixed requiere balance, no solo presencia de negativo

**CASO REAL COMPARABLE:**
```
Imagina estas dos reseÃ±as:

RESEÃ‘A 1:
"EstÃ¡ bien. Es aceptable. No estÃ¡ mal."
3 oraciones ligeramente positivas
â†’ Sentiment: NEUTRAL/POSITIVE (bajo)

RESEÃ‘A 2:  
"Â¡ODIO este lugar! Â¡HORRIBLE experiencia!"
2 oraciones extremadamente negativas
â†’ Sentiment: VERY NEGATIVE

La INTENSIDAD importa mÃ¡s que el CONTEO
```

**TIP PARA EL EXAMEN:**
El anÃ¡lisis de sentimiento es sobre PESO EMOCIONAL, no conteo estadÃ­stico de oraciones positivas vs negativas.

</details>

---

### Pregunta 5 - Threshold Configuration
**DIFICULTAD: ğŸŸ¡ Media**

**ESCENARIO:**
Una empresa configura un sistema automÃ¡tico que:
- Si sentiment = NEGATIVE con confidence >0.80 â†’ Alerta urgente al equipo
- Si sentiment = NEGATIVE con confidence 0.60-0.80 â†’ Cola de revisiÃ³n
- Si sentiment = NEGATIVE con confidence <0.60 â†’ Sin acciÃ³n

Reciben esta reseÃ±a:
```
"No estoy seguro sobre este producto. Tiene cosas buenas y malas."

Resultado:
{
  "sentiment": "neutral",
  "confidenceScores": {
    "positive": 0.28,
    "neutral": 0.45,
    "negative": 0.27
  }
}
```

**PREGUNTA:**
Â¿QuÃ© acciÃ³n tomarÃ¡ el sistema?

A) Alerta urgente (negative >0.80)  
B) Cola de revisiÃ³n (negative 0.60-0.80)  
C) Sin acciÃ³n automÃ¡tica  
D) Error, debe reprocessarse  

<details>
<summary>ğŸ‘‰ Ver respuesta y explicaciÃ³n</summary>

**RESPUESTA CORRECTA: C) Sin acciÃ³n automÃ¡tica**

**EXPLICACIÃ“N DETALLADA:**

```
ANÃLISIS DE LA CONFIGURACIÃ“N:

CONDICIONES:
1. Alerta urgente: sentiment = NEGATIVE AND confidence >0.80
2. Cola revisiÃ³n: sentiment = NEGATIVE AND confidence 0.60-0.80
3. Sin acciÃ³n: Todo lo demÃ¡s

RESULTADO RECIBIDO:
- Sentiment: NEUTRAL (NO negative)
- Confidence negative: 0.27 (muy bajo)

EVALUACIÃ“N:
CondiciÃ³n 1: âŒ (no es NEGATIVE)
CondiciÃ³n 2: âŒ (no es NEGATIVE)
CondiciÃ³n 3: âœ… (default)

ACCIÃ“N: Sin acciÃ³n automÃ¡tica
```

**RAZONAMIENTO:**
```
El sistema busca sentiment = NEGATIVE
Pero recibiÃ³ sentiment = NEUTRAL

Aunque hay 0.27 (27%) de negative en los scores,
el SENTIMIENTO PREDOMINANTE es NEUTRAL (0.45 = 45%)

Por lo tanto, NO cumple las condiciones de alerta
```

**CASO EDUCATIVO:**
Este es exactamente el tipo de reseÃ±a ambigua que:
- No dispara alertas automÃ¡ticas
- DeberÃ­a revisarse manualmente en un flujo completo
- Representa incertidumbre del usuario

**Por quÃ© las otras son incorrectas:**
- **A)** Requiere negative >0.80, pero es neutral con 0.27 negative
- **B)** Requiere negative 0.60-0.80, pero es neutral con 0.27 negative
- **D)** No hay error, es un resultado vÃ¡lido

**CONCEPTO CLAVE:**
```
DIFERENCIA IMPORTANTE:

sentiment: "negative" 
â†’ Es el TIPO predominante

confidenceScores.negative: 0.27
â†’ Es el PORCENTAJE de negatividad detectada

Para que actÃºe, necesitas:
sentiment == "negative" (predominante)
```

**TIP PARA EL EXAMEN:**
Lee cuidadosamente las CONDICIONES. El sistema evalÃºa el `sentiment` predominante, no los `confidenceScores` individuales.

</details>

---

### Pregunta 6 - Document vs Sentence Level
**DIFICULTAD: ğŸŸ¡ Media**

**ESCENARIO:**
Un analista revisa resultados de Sentiment Analysis y encuentra esto confuso:

```
DOCUMENTO COMPLETO: sentiment = "positive" (0.75)

ORACIONES:
1. "Excelente producto" â†’ positive (0.95)
2. "Muy recomendable" â†’ positive (0.92)
3. "Servicio al cliente terrible" â†’ negative (0.88)
4. "Gran calidad" â†’ positive (0.90)
```

**PREGUNTA:**
El analista pregunta: "Â¿CÃ³mo puede el documento ser 'positive' si hay una oraciÃ³n muy negativa?" Â¿CuÃ¡l es la mejor explicaciÃ³n?

A) Hay un error, deberÃ­a ser "mixed"  
B) El anÃ¡lisis de documento pondera todas las oraciones; 3 positivas fuertes superan 1 negativa  
C) El sistema ignora oraciones negativas minoritarias  
D) Solo la primera oraciÃ³n determina el sentimiento del documento  

<details>
<summary>ğŸ‘‰ Ver respuesta y explicaciÃ³n</summary>

**RESPUESTA CORRECTA: B) El anÃ¡lisis de documento pondera todas las oraciones; 3 positivas fuertes superan 1 negativa**

**EXPLICACIÃ“N DETALLADA:**

```
ANÃLISIS MATEMÃTICO (simplificado):

PESO EMOCIONAL:
OraciÃ³n 1: +0.95 (muy positiva)
OraciÃ³n 2: +0.92 (muy positiva)
OraciÃ³n 3: -0.88 (muy negativa)
OraciÃ³n 4: +0.90 (muy positiva)

PROMEDIO PONDERADO (aproximado):
(0.95 + 0.92 - 0.88 + 0.90) / 4 = 0.72 â‰ˆ 0.75

RESULTADO DOCUMENTO: POSITIVE (0.75)
```

**RAZONAMIENTO:**
```
3 ORACIONES MUY POSITIVAS (0.95, 0.92, 0.90)
vs
1 ORACIÃ“N MUY NEGATIVA (0.88)

La proporciÃ³n 3:1 positivo:negativo con pesos altos
â†’ Documento GENERAL es positivo

Pero el score no es 0.95 (altÃ­simo)
â†’ Es 0.75 (positivo pero mÃ¡s moderado)
â†’ Refleja que HAY contenido negativo
```

**ANALOGÃA:**
```
Si 3 personas califican un restaurante con 5â­
y 1 persona califica con 1â­

Promedio â‰ˆ 4 estrellas (positivo, pero no perfecto)
No es 5â­ (por el review negativo)
No es 2.5â­ (porque mayorÃ­a es positiva)
```

**Por quÃ© las otras son incorrectas:**
- **A)** No es error; positive es correcto cuando positivo > negativo significativamente
- **C)** No ignora nada; todas las oraciones influyen en el score final
- **D)** FALSO: Todas las oraciones contribuyen, no solo la primera

**CUÃNDO SERÃA "MIXED":**
```
Si fuera:
2 positivas (0.85, 0.88)
2 negativas (0.82, 0.86)

â†’ Balance mÃ¡s parejo â†’ MIXED

Pero 3 vs 1 con todas scores altos
â†’ Claro predominio positivo â†’ POSITIVE
```

**TIP PARA EL EXAMEN:**
Documento "positive" puede contener oraciones negativas si la proporciÃ³n y peso favorece claramente lo positivo. Mixed requiere balance mÃ¡s equitativo.

</details>

---

### Pregunta 7 - Active Learning en Opinion Mining
**DIFICULTAD: ğŸ”´ DifÃ­cil**

**ESCENARIO:**
Una cadena hotelera implementÃ³ Opinion Mining hace 3 meses. El sistema ahora detecta estos targets comÃºnmente:
- Habitaciones, WiFi, Desayuno, UbicaciÃ³n, Personal

Empiezan a recibir menciones de un nuevo target que el sistema NO reconoce bien:
"Las medidas de higiene COVID son excelentes"
"Protocolos sanitarios muy estrictos"
"Limpieza anti-COVID impecable"

**PREGUNTA:**
Â¿QuÃ© caracterÃ­stica de Azure AI Language les permite mejorar el sistema para reconocer "protocolos COVID/sanitarios" como un nuevo target?

A) Active Learning  
B) Custom Text Classification  
C) Sentiment Analysis avanzado  
D) Entity Linking  

<details>
<summary>ğŸ‘‰ Ver respuesta y explicaciÃ³n</summary>

**RESPUESTA CORRECTA: A) Active Learning**

**EXPLICACIÃ“N DETALLADA:**

```
PROBLEMA:
Nuevo concepto emergente: "Protocolos COVID/Sanitarios"
Sistema entrenado pre-COVID no reconoce este target

SOLUCIÃ“N: Active Learning
```

**CÃ“MO FUNCIONA ACTIVE LEARNING:**

```
PASO 1: SISTEMA DETECTA INCERTIDUMBRE
Recibe: "Protocolos sanitarios muy estrictos"
Sistema piensa: 
  "Â¿Es esto sobre 'Limpieza'? (60% seguro)
   Â¿Es un nuevo concepto? (40% seguro)"
â†’ Marca para revisiÃ³n humana

PASO 2: REVISIÃ“N HUMANA
Administrador revisa:
âœ… "SÃ­, es un nuevo target: 'Protocolos Sanitarios'"
âœ… Asocia estas frases al nuevo target

PASO 3: SISTEMA APRENDE
PrÃ³ximas menciones de:
- "protocolos COVID"
- "medidas sanitarias"
- "higiene COVID"
â†’ Se reconocen automÃ¡ticamente como target

PASO 4: MEJORA CONTINUA
El sistema ahora detecta este nuevo aspecto
en futuras reseÃ±as automÃ¡ticamente
```

**EJEMPLO PRÃCTICO:**

```
MES 1 (sin Active Learning):
"Los protocolos COVID son excelentes"
â†’ No detectado como target âŒ

MES 2 (con Active Learning - entrenamiento):
"Las medidas sanitarias son estrictas"
â†’ Marcado para revisiÃ³n
â†’ Admin confirma: nuevo target "Protocolos Sanitarios"

MES 3 (despuÃ©s de aprendizaje):
"Higiene COVID impecable"
â†’ AutomÃ¡ticamente detectado âœ…
â†’ Target: "Protocolos Sanitarios"
â†’ Sentiment: POSITIVE
```

**Por quÃ© las otras son incorrectas:**
- **B)** Custom Text Classification es para categorÃ­as completas, no targets de Opinion Mining
- **C)** Sentiment Analysis NO aprende nuevos targets, solo detecta sentimiento
- **D)** Entity Linking vincula a Wikipedia, no aprende targets nuevos

**CONCEPTO CLAVE:**
```
ACTIVE LEARNING:
- Sistema mejora CON EL USO
- Aprende de correcciones humanas
- Se adapta a nuevos conceptos
- ComÃºn en producciÃ³n real

STATIC MODEL:
- No cambia despuÃ©s de deployment
- Requiere re-entrenamiento manual
- No se adapta a cambios
```

**CASO REAL:**
```
2019: Hoteles mencionaban "WiFi", "Desayuno"
2020: Aparece "Protocolos COVID" como tema importante
2021: Aparece "Trabajo remoto" como necesidad
2023: Aparece "Cargadores EV" en hoteles modernos

Active Learning permite adaptarse a estos cambios
sin re-entrenar completamente el modelo
```

**TIP PARA EL EXAMEN:**
Active Learning = El sistema APRENDE y se MEJORA automÃ¡ticamente con feedback humano en producciÃ³n

</details>

---

### Pregunta 8 - Metadata Filtering en Opinion Mining
**DIFICULTAD: ğŸ”´ DifÃ­cil**

**ESCENARIO:**
Una aerolÃ­nea analiza feedback de pasajeros. Tienen 3 clases de servicio:
- EconÃ³mica
- Premium Economy  
- Business

Un pasajero escribe:
"La comida era excelente y el espacio muy cÃ³modo"

**PREGUNTA:**
La aerolÃ­nea quiere que Opinion Mining devuelva respuestas contextuales:
- Si es clase EconÃ³mica â†’ Comparar con estÃ¡ndares de econÃ³mica
- Si es clase Business â†’ Comparar con estÃ¡ndares de business

Â¿QuÃ© caracterÃ­stica de Azure AI Language necesitan configurar?

A) Multi-turn conversations  
B) Metadata filtering  
C) Custom entities  
D) Sentiment thresholds  

<details>
<summary>ğŸ‘‰ Ver respuesta y explicaciÃ³n</summary>

**RESPUESTA CORRECTA: B) Metadata filtering**

**EXPLICACIÃ“N DETALLADA:**

```
PROBLEMA:
"Espacio cÃ³modo" significa cosas diferentes:

En EconÃ³mica: 
- 80cm de espacio = "cÃ³modo" (comparado con tÃ­pico 75cm)

En Business:
- 80cm de espacio = "estrecho" (comparado con tÃ­pico 120cm)

NECESITAN: Respuestas contextuales basadas en clase
```

**CÃ“MO FUNCIONA METADATA FILTERING:**

```
CONFIGURACIÃ“N EN KB:

ENTRADA 1:
Pregunta: "Â¿CÃ³mo es el espacio?"
Respuesta: "El espacio es adecuado para vuelos cortos"
Metadata: {"clase": "economica"}

ENTRADA 2:
Pregunta: "Â¿CÃ³mo es el espacio?"
Respuesta: "El espacio es amplio con asientos reclinables"
Metadata: {"clase": "business"}
```

**USO EN PRODUCCIÃ“N:**

```
CASO 1:
Pasajero de EconÃ³mica
Context: {"clase": "economica"}
Opinion Mining sobre "espacio":
â†’ Usa estÃ¡ndares de econÃ³mica
â†’ "cÃ³modo" = Bueno comparado con econÃ³mica tÃ­pica

CASO 2:
Pasajero de Business
Context: {"clase": "business"}
Opinion Mining sobre "espacio":
â†’ Usa estÃ¡ndares de business
â†’ "cÃ³modo" = MÃ­nimo aceptable para business
```

**EJEMPLO REAL COMPLETO:**

```
RESEÃ‘A: "La comida era excelente y el espacio cÃ³modo"
CLASE: Business
METADATA: {"clase": "business"}

OPINION MINING RESULTADO:
Target: "comida"
Assessment: "excelente"  
Sentiment: POSITIVE
Context: "Cumple expectativas premium" âœ…

Target: "espacio"
Assessment: "cÃ³modo"
Sentiment: NEUTRAL/POSITIVE
Context: "Adecuado pero no excepcional para Business" âš ï¸
```

**Por quÃ© las otras son incorrectas:**
- **A)** Multi-turn es para conversaciones en varios pasos, no contexto de clase
- **C)** Custom entities detectan tipos de datos, no cambian interpretaciÃ³n contextual
- **D)** Thresholds son para confianza, no para contexto

**OTROS USOS DE METADATA:**

```
E-COMMERCE:
Metadata: {"categoria": "electronica"} vs {"categoria": "ropa"}
â†’ "Dura poco" tiene significado diferente
â†’ ElectrÃ³nico: problema de calidad
â†’ Ropa: tendencia de moda pasajera

HOTELES:
Metadata: {"tipo": "resort"} vs {"tipo": "business"}
â†’ "Tranquilo" tiene valor diferente
â†’ Resort: Â¡Positivo! (relax)
â†’ Business: Â¿Negativo? (falta actividad)
```

**TIP PARA EL EXAMEN:**
Metadata filtering permite respuestas CONTEXTUALES - la misma frase puede interpretarse diferente segÃºn el contexto del usuario/producto.

</details>

---

### Pregunta 9 - Confidence Score Edge Case
**DIFICULTAD: ğŸ”´ DifÃ­cil**

**ESCENARIO:**
Un analista recibe estos dos resultados:

```
TEXTO A: "Â¡IncreÃ­ble! Â¡Perfecto! Â¡Me encanta!"
{
  "sentiment": "positive",
  "confidenceScores": {
    "positive": 0.99,
    "neutral": 0.01,
    "negative": 0.00
  }
}

TEXTO B: "OK"
{
  "sentiment": "positive",
  "confidenceScores": {
    "positive": 0.48,
    "neutral": 0.47,
    "negative": 0.05
  }
}
```

**PREGUNTA:**
Â¿CuÃ¡l afirmaciÃ³n es VERDADERA sobre estos resultados?

A) Ambos son igualmente confiables porque ambos tienen sentiment "positive"  
B) Texto A es muy confiable; Texto B estÃ¡ en el lÃ­mite y podrÃ­a beneficiarse de revisiÃ³n manual  
C) Texto B es invÃ¡lido porque positive (0.48) no es mayorÃ­a clara  
D) Ambos requieren re-procesamiento por tener scores tan diferentes  

<details>
<summary>ğŸ‘‰ Ver respuesta y explicaciÃ³n</summary>

**RESPUESTA CORRECTA: B) Texto A es muy confiable; Texto B estÃ¡ en el lÃ­mite y podrÃ­a beneficiarse de revisiÃ³n manual**

**EXPLICACIÃ“N DETALLADA:**

```
ANÃLISIS PROFUNDO:

TEXTO A: "Â¡IncreÃ­ble! Â¡Perfecto! Â¡Me encanta!"
âœ… Sentiment: POSITIVE
âœ… Confidence: 0.99 (ALTÃSIMA)
âœ… Sin ambigÃ¼edad
âœ… AcciÃ³n: Confiar completamente

TEXTO B: "OK"
âœ… Sentiment: POSITIVE (tÃ©cnicamente)
âš ï¸ Confidence: 0.48 (BAJA)
âš ï¸ Neutral muy cercano: 0.47
âš ï¸ Alta ambigÃ¼edad
âš ï¸ AcciÃ³n: RevisiÃ³n manual recomendada
```

**Â¿POR QUÃ‰ TEXTO B ES AMBIGUO?**

```
"OK" puede significar:

CONTEXTO 1:
P: "Â¿Te gustÃ³ la pelÃ­cula?"
R: "OK" â†’ Meh, regular (NEUTRAL)

CONTEXTO 2:
P: "Â¿Funciona el sistema?"
R: "OK" â†’ SÃ­, funciona (NEUTRAL/POSITIVE)

CONTEXTO 3:
P: "Â¿Apruebas el plan?"
R: "OK" â†’ Acepto (POSITIVE)

La palabra "OK" es inherentemente ambigua
â†’ Explica los scores casi iguales (0.48 vs 0.47)
```

**ESTRATEGIA EMPRESARIAL RECOMENDADA:**

```
TIER 1 - ALTA CONFIANZA (>0.85):
Action: Procesamiento automÃ¡tico completo
Ejemplo: Texto A (0.99)

TIER 2 - MEDIA CONFIANZA (0.65-0.85):
Action: Procesamiento automÃ¡tico + muestreo aleatorio
Ejemplo: "El producto es bueno" (0.75)

TIER 3 - BAJA CONFIANZA (<0.65):
Action: Marcar para revisiÃ³n manual
Ejemplo: Texto B (0.48)
```

**Por quÃ© las otras son incorrectas:**
- **A)** NO son igualmente confiables; 0.99 >> 0.48 en confiabilidad
- **C)** NO es invÃ¡lido; es vÃ¡lido pero con baja certeza
- **D)** NO necesitan re-procesamiento; son resultados correctos

**CONCEPTO IMPORTANTE:**

```
MISMO SENTIMENT â‰  MISMA CONFIANZA

"positive" con 0.99 â†’ CERTEZA ABSOLUTA
"positive" con 0.48 â†’ APENAS POSITIVO

Es como decir:
"99% seguro que es positivo" vs "48% seguro que es positivo"
```

**CASO REAL:**

```
EMPRESA DE SOPORTE:
Analiza 10,000 tickets

HIGH CONFIDENCE (7,000 tickets):
â†’ Procesamiento automÃ¡tico âœ…

LOW CONFIDENCE (3,000 tickets):
â†’ RevisiÃ³n humana
â†’ Descubren: mayorÃ­a son casos edge
   * Sarcasmo
   * Contexto cultural
   * Abreviaturas
   * Lenguaje informal

RESULTADO: Mejora en satisfacciÃ³n del cliente
```

**TIP PARA EL EXAMEN:**
Mismo sentiment label no significa misma confiabilidad. Confidence scores bajos (<0.60) requieren atenciÃ³n adicional incluso si el sentiment parece claro.

</details>

---

### Pregunta 10 - Real-Time Dashboard
**DIFICULTAD: ğŸŸ¡ Media**

**ESCENARIO:**
Una empresa de delivery de comida quiere un dashboard en tiempo real que muestre:

```
DASHBOARD REQUERIDO:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SENTIMIENTO GENERAL: 78% Positivo   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ASPECTOS:                           â”‚
â”‚ â€¢ Rapidez: 85% positivo âœ…          â”‚
â”‚ â€¢ Calidad comida: 72% positivo âœ…   â”‚
â”‚ â€¢ Empaque: 90% positivo âœ…          â”‚
â”‚ â€¢ Precio: 45% positivo âš ï¸           â”‚
â”‚ â€¢ App: 68% positivo âœ…              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ALERTAS AUTOMÃTICAS cuando:
- Cualquier aspecto cae <50% positivo
```

**PREGUNTA:**
Â¿QuÃ© combinaciÃ³n de servicios Azure necesitan?

A) Sentiment Analysis (documento) + Azure Monitor para alertas  
B) Opinion Mining + Stream Analytics + Power BI para dashboard + Logic Apps para alertas  
C) Solo Question Answering con knowledge base de reseÃ±as  
D) Named Entity Recognition + Sentiment Analysis  

<details>
<summary>ğŸ‘‰ Ver respuesta y explicaciÃ³n</summary>

**RESPUESTA CORRECTA: B) Opinion Mining + Stream Analytics + Power BI para dashboard + Logic Apps para alertas**

**EXPLICACIÃ“N DETALLADA:**

```
ARQUITECTURA COMPLETA:

1. OPINION MINING (Azure AI Language):
   Input: ReseÃ±as de clientes
   Output: Targets + Sentiments
   
   Ejemplo:
   "Rapidez excelente pero muy caro"
   â†’ Target: Rapidez, Sentiment: POSITIVE
   â†’ Target: Precio, Sentiment: NEGATIVE

2. STREAM ANALYTICS:
   Procesa reseÃ±as en tiempo real
   Calcula estadÃ­sticas agregadas
   
   Query ejemplo:
   SELECT 
     Target,
     COUNT(*) as Total,
     SUM(CASE WHEN Sentiment='positive' THEN 1 END) / COUNT(*) as PositiveRate
   FROM ReviewStream
   GROUP BY Target, TumblingWindow(minute, 5)

3. POWER BI:
   VisualizaciÃ³n del dashboard
   ActualizaciÃ³n en tiempo real
   GrÃ¡ficos por aspecto

4. LOGIC APPS:
   Monitorea mÃ©tricas
   Dispara alertas cuando PositiveRate < 0.50
   Notifica a equipo via email/Teams
```

**FLUJO COMPLETO:**

```
TIEMPO REAL:

09:00 AM - ReseÃ±a nueva:
"Entrega rÃ¡pida pero la comida llegÃ³ frÃ­a"

â†“ Opinion Mining procesa
Target: Entrega â†’ POSITIVE
Target: Comida â†’ NEGATIVE

â†“ Stream Analytics agrega
Calidad Comida: ahora 48% positivo (bajÃ³ de 72%)

â†“ Logic App detecta
48% < 50% â†’ TRIGGER ALERT

â†“ NotificaciÃ³n
Email a gerente de cocina:
"âš ï¸ ALERTA: Calidad comida cayÃ³ a 48%"

â†“ Dashboard actualiza
Power BI muestra grÃ¡fico en rojo
```

**Por quÃ© las otras son incorrectas:**

- **A)** Sentiment Analysis solo da sentimiento general, NO por aspecto
  
- **C)** Question Answering NO hace anÃ¡lisis de sentimiento; solo responde preguntas de KB

- **D)** NER + Sentiment NO identifica targets de opiniÃ³n (como "rapidez", "precio")

**COMPONENTES CRÃTICOS:**

```
Â¿POR QUÃ‰ NECESITAS CADA SERVICIO?

OPINION MINING:
â†’ Sin esto, no puedes desglosar por aspecto
â†’ Sentiment solo darÃ­a tono general

STREAM ANALYTICS:
â†’ Sin esto, no puedes procesar tiempo real
â†’ No puedes agregar estadÃ­sticas dinÃ¡micas

POWER BI:
â†’ Sin esto, no tienes dashboard visual
â†’ PodrÃ­as usar otra herramienta de BI

LOGIC APPS:
â†’ Sin esto, no hay alertas automÃ¡ticas
â†’ PodrÃ­as usar Azure Functions tambiÃ©n
```

**TIP PARA EL EXAMEN:**
"Dashboard en tiempo real con desglose por aspectos" = Opinion Mining + herramientas de streaming y visualizaciÃ³n

</details>

---

## ğŸ“Š SECCIÃ“N 2: EXTRACCIÃ“N DE INFORMACIÃ“N (8 preguntas)

### Pregunta 11 - Key Phrases vs NER en IndexaciÃ³n
**DIFICULTAD: ğŸŸ¡ Media**

**ESCENARIO:**
Una biblioteca digital tiene 100,000 artÃ­culos acadÃ©micos. Quieren dos sistemas de bÃºsqueda diferentes:

**SISTEMA A:** BÃºsqueda por tema/concepto
- Usuario busca: "inteligencia artificial"
- Devuelve: ArtÃ­culos donde IA es tema principal

**SISTEMA B:** BÃºsqueda por persona/organizaciÃ³n
- Usuario busca: "Microsoft"
- Devuelve: ArtÃ­culos que mencionan Microsoft especÃ­ficamente

**PREGUNTA:**
Â¿QuÃ© servicios deben usar para cada sistema?

A) Ambos usan Key Phrase Extraction  
B) Ambos usan Named Entity Recognition  
C) Sistema A: Key Phrase Extraction; Sistema B: Named Entity Recognition  
D) Sistema A: Sentiment Analysis; Sistema B: Key Phrase Extraction  

<details>
<summary>ğŸ‘‰ Ver respuesta y explicaciÃ³n</summary>

**RESPUESTA CORRECTA: C) Sistema A: Key Phrase Extraction; Sistema B: Named Entity Recognition**

**EXPLICACIÃ“N DETALLADA:**

```
SISTEMA A - BÃšSQUEDA POR TEMA:

ArtÃ­culo ejemplo:
"Este paper explora machine learning aplicado a medicina.
EspecÃ­ficamente, analizamos redes neuronales para diagnÃ³stico
de enfermedades cardÃ­acas."

KEY PHRASE EXTRACTION detecta:
âœ… "machine learning"
âœ… "medicina"
âœ… "redes neuronales"
âœ… "diagnÃ³stico"
âœ… "enfermedades cardÃ­acas"

Usuario busca: "machine learning medicina"
â†’ Este artÃ­culo aparece (tema match) âœ…
```

```
SISTEMA B - BÃšSQUEDA POR ENTIDAD:

ArtÃ­culo ejemplo:
"El estudio fue realizado en colaboraciÃ³n con Microsoft Research
y la Universidad de Stanford. Los datos se procesaron usando Azure."

NER detecta:
âœ… Microsoft Research (Organization)
âœ… Universidad de Stanford (Organization)
âœ… Azure (Product)

Usuario busca: "Microsoft"
â†’ Este artÃ­culo aparece (entidad match) âœ…
```

**DIFERENCIA CLAVE:**

```
KEY PHRASES (conceptos generales):
- "inteligencia artificial" (tema)
- "cambio climÃ¡tico" (tema)
- "polÃ­tica econÃ³mica" (tema)
â†’ PARA: ClasificaciÃ³n temÃ¡tica

NER (entidades especÃ­ficas):
- "Microsoft" (organizaciÃ³n)
- "Bill Gates" (persona)
- "Seattle" (lugar)
â†’ PARA: Referencias especÃ­ficas
```

**CASO REAL:**

```
BÃšSQUEDA: "inteligencia artificial"

CON KEY PHRASES:
Encuentra artÃ­culos donde "IA" es tema central
â†’ 5,000 resultados relevantes âœ…

CON NER:
Solo encuentra si "Inteligencia Artificial" 
es nombre de organizaciÃ³n/producto
â†’ 50 resultados (mayormente falsos positivos) âŒ

CONCLUSIÃ“N:
Key Phrases mejor para temas
NER mejor para entidades nombradas
```

**Por quÃ© las otras son incorrectas:**
- **A)** Key Phrases NO es Ã³ptimo para nombres de organizaciones
- **B)** NER NO es Ã³ptimo para conceptos generales
- **D)** Sentiment Analysis no ayuda en bÃºsqueda de contenido

**TIP PARA EL EXAMEN:**
```
Â¿BUSCAR POR QUÃ‰? â†’ Key Phrase Extraction
Â¿BUSCAR POR QUIÃ‰N/DÃ“NDE? â†’ Named Entity Recognition
```

</details>

---

### Pregunta 12 - PII Detection con RedacciÃ³n
**DIFICULTAD: ğŸŸ¡ Media**

**ESCENARIO:**
Un hospital debe publicar transcripciones anonimizadas de consultas para investigaciÃ³n mÃ©dica. Tienen esta transcripciÃ³n:

```
"Paciente: Juan PÃ©rez, DNI 12345678A, edad 45 aÃ±os.
DirecciÃ³n: Calle Mayor 123, Madrid.
Email: juan.perez@email.com
DiagnÃ³stico: HipertensiÃ³n arterial con presiÃ³n 140/90.
PrescripciÃ³n: Enalapril 10mg, seguimiento en 3 meses."
```

**PREGUNTA:**
Quieren publicar: mantener informaciÃ³n mÃ©dica pero eliminar datos identificables. Â¿QuÃ© configuraciÃ³n de PII Detection necesitan?

A) Detectar y redactar todas las entidades incluyendo diagnÃ³stico  
B) Detectar Person, ID, Address, Email pero NO redactar tÃ©rminos mÃ©dicos  
C) Solo usar Sentiment Analysis  
D) No pueden usar PII Detection porque es espaÃ±ol  

<details>
<summary>ğŸ‘‰ Ver respuesta y explicaciÃ³n</summary>

**RESPUESTA CORRECTA: B) Detectar Person, ID, Address, Email pero NO redactar tÃ©rminos mÃ©dicos**

**EXPLICACIÃ“N DETALLADA:**

```
CONFIGURACIÃ“N DE PII DETECTION:

piiCategories: [
  "Person",           // Juan PÃ©rez
  "SpainIdentityCard", // 12345678A
  "Address",          // Calle Mayor 123
  "Email"             // juan.perez@email.com
]

NO INCLUIR:
âŒ TÃ©rminos mÃ©dicos (no son PII)
âŒ Edad (puede ser relevante para investigaciÃ³n)
âŒ Medicamentos (informaciÃ³n mÃ©dica necesaria)
```

**RESULTADO DE REDACCIÃ“N:**

```
TEXTO ORIGINAL:
"Paciente: Juan PÃ©rez, DNI 12345678A, edad 45 aÃ±os.
DirecciÃ³n: Calle Mayor 123, Madrid.
Email: juan.perez@email.com
DiagnÃ³stico: HipertensiÃ³n arterial con presiÃ³n 140/90.
PrescripciÃ³n: Enalapril 10mg, seguimiento en 3 meses."

TEXTO REDACTADO:
"Paciente: [PERSON], DNI [ID], edad 45 aÃ±os.
DirecciÃ³n: [ADDRESS], Madrid.
Email: [EMAIL]
DiagnÃ³stico: HipertensiÃ³n arterial con presiÃ³n 140/90.
PrescripciÃ³n: Enalapril 10mg, seguimiento en 3 meses."
```

**UTILIDAD PARA INVESTIGACIÃ“N:**

```
DATOS PRESERVADOS (Ãºtiles):
âœ… Edad: 45 aÃ±os
âœ… UbicaciÃ³n general: Madrid
âœ… DiagnÃ³stico: HipertensiÃ³n arterial
âœ… PresiÃ³n: 140/90
âœ… Tratamiento: Enalapril 10mg
âœ… Timeline: seguimiento 3 meses

DATOS REMOVIDOS (identificables):
âŒ Nombre especÃ­fico
âŒ DNI
âŒ DirecciÃ³n exacta
âŒ Email

RESULTADO:
Investigadores pueden analizar patrones mÃ©dicos
SIN poder identificar pacientes individuales âœ…
```

**HIPAA COMPLIANCE:**

```
HIPAA requiere eliminar 18 tipos de identificadores:
1. Nombres âœ…
2. Direcciones (mÃ¡s especÃ­fico que ciudad/estado) âœ…
3. Fechas (excepto aÃ±o)
4. NÃºmeros de telÃ©fono âœ…
5. NÃºmeros de seguridad social âœ…
6. NÃºmeros de historia clÃ­nica âœ…
7. Email âœ…
...

PII Detection de Azure cubre estos tipos
â†’ Facilita compliance automÃ¡tico
```

**Por quÃ© las otras son incorrectas:**
- **A)** NO deben redactar diagnÃ³stico; es informaciÃ³n mÃ©dica necesaria
- **C)** Sentiment Analysis NO detecta ni redacta PII
- **D)** PII Detection SÃ funciona en espaÃ±ol

**CONFIGURACIÃ“N ADICIONAL POSIBLE:**

```
Si necesitan MÃS privacidad:

OPCIÃ“N 1 - Generalizar edad:
"45 aÃ±os" â†’ "40-50 aÃ±os"

OPCIÃ“N 2 - Generalizar ubicaciÃ³n:
"Madrid" â†’ "Comunidad de Madrid"

OPCIÃ“N 3 - Usar IDs de investigaciÃ³n:
[PERSON] â†’ "PARTICIPANT_001"
```

**TIP PARA EL EXAMEN:**
PII Detection es CONFIGURABLE - puedes elegir QUÃ‰ categorÃ­as detectar/redactar segÃºn tus necesidades de compliance vs utilidad de datos.

</details>

---

[ContinÃºo con las preguntas restantes...]

---

**Â¿Te sigo generando las 30 preguntas restantes (Pregunta 13-40)?**

Este banco estÃ¡ diseÃ±ado para:
- âœ… Casos mÃ¡s realistas y complejos
- âœ… Escenarios empresariales verdaderos
- âœ… Mayor profundidad en explicaciones
- âœ… Dificultad progresiva

**Ya tienes 12 preguntas completas. Â¿Quieres que continÃºe con las otras 28?** ğŸ¯
